{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib qt\n",
    "\n",
    "#This notebook is a testbed for importing PEAC Center USAPI\n",
    "#raifnall data using pandas and doing some quick analysis\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as cols\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap, shiftgrid\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "from datetime import date\n",
    "import datetime\n",
    "\n",
    "import calendar\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "from scipy import signal, linalg, stats\n",
    "\n",
    "from pycurrents.codas import to_day, to_date\n",
    "from pycurrents.plot.mpltools import dday_to_mpl\n",
    "\n",
    "from pycurrents.system import Bunch\n",
    "from pycurrents.num import eof\n",
    "from pycurrents.num import rangeslice\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '/home/alejandro/Desktop/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extend(dday_1800, dat):\n",
    "    \"\"\"\n",
    "    Return dday, dat extended to fill out the last year.\n",
    "    \n",
    "    This function was modifyed to take in only one data variable.\n",
    "    \"\"\"\n",
    "    n_orig = len(dday_1800)\n",
    "    ymdhms = to_date(1800, dday_1800)\n",
    "    nmissing = 12 - ymdhms[-1, 1]\n",
    "    nmonths = n_orig + nmissing\n",
    "    ymdhms_new = np.zeros((nmonths, 6), dtype=np.uint16)\n",
    "    ymdhms_new[:n_orig, :] = ymdhms\n",
    "    ymdhms_new[n_orig:, 0] = ymdhms[-1, 0]\n",
    "    # Fill in the remaining months:\n",
    "    ymdhms_new[n_orig:, 1] = np.arange(ymdhms[-1, 1] + 1, 13)\n",
    "    ymdhms_new[n_orig:, 2] = 1\n",
    "    dday_new = to_day(1800, ymdhms_new)\n",
    "    \n",
    "    shape_new = (nmonths, dat.shape[1], dat.shape[2])\n",
    "    ## EF: modify to work with masked array or ndarray\n",
    "    if np.ma.isMA(dat):\n",
    "        dat_new = np.ma.masked_all(shape_new, float)\n",
    "    else:    \n",
    "        dat_new = np.nan + np.zeros(shape_new, float)\n",
    "    \n",
    "    dat_new[:n_orig, :, :] = dat\n",
    "    \n",
    "    #This Function has been modifyed to also return the date of the last valid data and its ymdhms index\n",
    "    \n",
    "    last_valid_date = to_date(1800,dday_1800[-1])\n",
    "    last_valid_index = n_orig -1\n",
    "   \n",
    "    return Bunch(dday_1800=dday_new,\n",
    "                 ymdhms=ymdhms_new,\n",
    "                 dat=dat_new,\n",
    "                 last_valid_date=last_valid_date,\n",
    "                 last_valid_index=last_valid_index)\n",
    "\n",
    "def cal_climatology_and_anomaly(data,ymdhms,last_valid_date,last_valid_index,latitudes,longitudes,start_year, end_year):\n",
    "                           \n",
    "    #Select the years for climatology from the new ymdhms_padded\n",
    "    # All the monthly data for the years you want to calculate the climatology\n",
    "    \n",
    "    clim_selection = ((ymdhms[:, 0] >= start_year) & (ymdhms[:, 0] <= end_year))\n",
    "    \n",
    "    # EF: Trim everything right at the start.\n",
    "    data = data[clim_selection]\n",
    "    ymdhms = ymdhms[clim_selection]\n",
    "    \n",
    "    #Calculate the total numbers of years in the climatology\n",
    "    length_in_years = ymdhms[-1, 0] - ymdhms[0, 0] + 1\n",
    "    \n",
    "    # EF: ensure we have masked arrays and no nans\n",
    "    data = np.ma.masked_invalid(data)\n",
    "    \n",
    "    #reshape the matrix so that is has dimensions of [years, months, lat, lon]\n",
    "    reshaped_data = np.reshape(data, (length_in_years, 12, \n",
    "                                      len(latitudes), \n",
    "                                      len(longitudes)))\n",
    "    #Calculate the climatology by using nanmeans, along the yeas axis\n",
    "    #climatology = np.nanmean(reshaped_data, axis=0)\n",
    "    \n",
    "    climatology = reshaped_data.mean(axis=0)\n",
    "    anomaly = reshaped_data - climatology\n",
    "    anomaly = anomaly.reshape(data.shape)\n",
    "    \n",
    "    if end_year < last_valid_date[0]:\n",
    "        last_valid_date_new = ymdhms[-1,:]\n",
    "        last_valid_index_new = -1\n",
    "    else:\n",
    "        last_valid_date_new = last_valid_date\n",
    "        last_valid_index_new = np.where((ymdhms[:,0]== last_valid_date[0]) &\n",
    "                                        (ymdhms[:,1]== last_valid_date[1]) &\n",
    "                                        (ymdhms[:,2]== last_valid_date[2]))[0][0]\n",
    "    \n",
    "    return Bunch(climatology=climatology,\n",
    "                 anomaly=anomaly, \n",
    "                 ymdhms=ymdhms,\n",
    "                 last_valid_date = last_valid_date_new,\n",
    "                 last_valid_index = last_valid_index_new)\n",
    "\n",
    "def seasonal_anomaly(m_anom,last_valid_index):\n",
    "    s_anom = np.ma.zeros(m_anom.shape, float)\n",
    "    orig_mask = np.ma.getmaskarray(m_anom)\n",
    "    \n",
    "    if last_valid_index == -1:\n",
    "        s_anom[1:-1] = (m_anom[:-2] + m_anom[1:-1] + m_anom[2:]) / 3\n",
    "    \n",
    "        s_anom[0] = (m_anom[0] + m_anom[1]) / 2\n",
    "        s_anom[-1] = (m_anom[-2] + m_anom[-1]) / 2\n",
    "    \n",
    "    else:\n",
    "        #s_anom[1:last_valid_index-1,:,:] = (m_anom[:last_valid_index-2,:,:] + \n",
    "        #                                    m_anom[1:last_valid_index-1,:,:] + \n",
    "        #                                    m_anom[2:last_valid_index,:,:]) / 3\n",
    "        s_anom[1:last_valid_index,:,:] = (m_anom[:last_valid_index-1,:,:] + \n",
    "                                          m_anom[1:last_valid_index,:,:] + \n",
    "                                          m_anom[2:last_valid_index+1,:,:]) / 3\n",
    "    \n",
    "        s_anom[0,:,:] = (m_anom[0,:,:] + m_anom[1,:,:]) / 2\n",
    "        s_anom[last_valid_index,:,:] = (m_anom[last_valid_index-1,:,:] + \n",
    "                                        m_anom[last_valid_index,:,:]) / 2\n",
    "        \n",
    "    s_anom_out = np.ma.array(s_anom, mask=orig_mask)\n",
    "    \n",
    "    return Bunch(s_anom = s_anom_out, \n",
    "                 last_valid_index = last_valid_index)\n",
    "\n",
    "def seasonal_anomaly2(m_anom, nmin=2):\n",
    "    newshape = [3] + list(m_anom.shape)\n",
    "    newshape[1] += 2\n",
    "    accum = np.ma.zeros(newshape, dtype=m_anom.dtype)\n",
    "    accum[:] = np.ma.masked\n",
    "    accum[0, :-2] = m_anom[:]\n",
    "    accum[1, 1:-1] = m_anom[:]\n",
    "    accum[2, 2:] = m_anom[:]\n",
    "    out = accum.mean(axis=0)[1:-1]\n",
    "    out = np.ma.masked_where(accum[:, 1:-1].count(axis=0) < nmin, out, copy=False)\n",
    "    return Bunch(s_anom = out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sst_seasonal_anom = seasonal_anomaly(sst_ca.anomaly, sst_ca.last_valid_index)\n",
    "#sst_seasonal_anom2 = seasonal_anomaly2(sst_ca.anomaly, nmin=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(sst_seasonal_anom.s_anom.shape)\n",
    "#print(sst_seasonal_anom2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.ma.allclose(sst_seasonal_anom.s_anom, sst_seasonal_anom2, masked_equal = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(c_PREC_precip_2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we read and process the time series data from the excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guam', 'Saipan', 'Koror', 'Yap', 'Chuuk', 'Pohnpei', 'Majuro', 'Kwajalein', 'PagoPago', 'Saipan_old', 'JFM', 'FMA', 'MAM', 'AMJ', 'MJJ', 'JJA', 'JAS', 'ASO', 'SON', 'OND', 'NDJ', 'DJF']\n",
      "['ONI']\n"
     ]
    }
   ],
   "source": [
    "peac_station_rain = pd.ExcelFile(datadir +'PEAC_station_rainfall_database.xlsx')\n",
    "print(peac_station_rain.sheet_names)\n",
    "\n",
    "ONI_file = pd.ExcelFile(datadir +'CPC_ONI.xlsx')\n",
    "print(ONI_file.sheet_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_USAPI_data(file_name, island_name):\n",
    "    \n",
    "    #Here we read the data into python from the excel file\n",
    "    raw_data= pd.read_excel(file_name, sheetname = island_name, \n",
    "                            skiprows = 1, parse_cols = \"A:O\")\n",
    "    \n",
    "    #\n",
    "    raw_matrix = raw_data.as_matrix(columns=None)\n",
    "    print(type(raw_matrix), raw_matrix.dtype)\n",
    "    \n",
    "    years =  raw_matrix[:51,1]\n",
    "    station_id = raw_matrix[0,0]\n",
    "\n",
    "    rainfall = raw_matrix[:51,3:]\n",
    "\n",
    "    rainfall[rainfall == '9999'] = np.nan\n",
    "    rainfall[rainfall == \"nan\"] = np.nan\n",
    "\n",
    "    rainfall = rainfall * 0.1\n",
    "    \n",
    "    # We have to convert from an object array to floating point.\n",
    "    rainfall = np.ma.masked_invalid(rainfall.astype(float))\n",
    "    print('rainfall: ', rainfall.dtype, rainfall[5, 5])\n",
    " \n",
    "    #Initiate the ymdhms array as an array of int values filler with zeros\n",
    "    #that has the length og the total number of time steps years*months\n",
    "    ymdhms = np.zeros([51*12,6],dtype = np.int)\n",
    "\n",
    "    #here we will the first column with the year values from the excel sheet. \n",
    "    #repeated each one 12 consecutive times\n",
    "    ymdhms[:,0] = np.repeat(years,12)\n",
    "\n",
    "    #Here we create a list of the month indices\n",
    "    m = np.arange(1,13)\n",
    "    #we tile the list so that the entire list 1..12 repeats as many times as the number of years\n",
    "    mm = np.tile(m,51)\n",
    "\n",
    "    ymdhms[:,1] = mm\n",
    "\n",
    "    #the day column is filled with 15\n",
    "    ymdhms[:,2] = 15\n",
    "    \n",
    "    dday = to_day(1800, ymdhms)\n",
    "    mpldays = dday_to_mpl(1800, dday)\n",
    "    mpldaysformated = mpl.dates.num2date(mpldays)\n",
    "\n",
    "    out = Bunch(island_name = island_name, station_id = station_id, rainfall=rainfall,\n",
    "               ymdhms = ymdhms, mpldaysformated = mpldaysformated)\n",
    "    \n",
    "    return out\n",
    "    #return station_id, rainfall, ymdhms, mpldaysformated\n",
    "    \n",
    "def read_index_data(file_name, index_name):\n",
    "    \n",
    "    #Here we read the data into python from the excel file\n",
    "    raw_data= pd.read_excel(file_name, sheetname = index_name, skiprows = 1, parse_cols = \"A:M\")\n",
    "    \n",
    "    #\n",
    "    raw_matrix = raw_data.as_matrix(columns=None)\n",
    "    print(type(raw_matrix), raw_matrix.dtype)\n",
    "    \n",
    "    years =  raw_matrix[:,0]\n",
    "    index = raw_matrix[:,1:]\n",
    "    \n",
    "\n",
    "    # We have to convert from an object array to floating point.\n",
    "    index = np.ma.masked_invalid(index.astype(float))\n",
    "    print('index: ', index.dtype, index[5, 5])\n",
    " \n",
    "    #Initiate the ymdhms array as an array of int values filler with zeros\n",
    "    #that has the length og the total number of time steps years*months\n",
    "    ymdhms = np.zeros([67*12,6],dtype = np.int)\n",
    "\n",
    "    #here we will the first column with the year values from the excel sheet. \n",
    "    #repeated each one 12 consecutive times\n",
    "    ymdhms[:,0] = np.repeat(years,12)\n",
    "\n",
    "    #Here we create a list of the month indices\n",
    "    m = np.arange(1,13)\n",
    "    #we tile the list so that the entire list 1..12 repeats as many times as the number of years\n",
    "    mm = np.tile(m,67)\n",
    "\n",
    "    ymdhms[:,1] = mm\n",
    "\n",
    "    #the day column is filled with 15\n",
    "    ymdhms[:,2] = 15\n",
    "    \n",
    "    dday = to_day(1800, ymdhms)\n",
    "    mpldays = dday_to_mpl(1800, dday)\n",
    "    mpldaysformated = mpl.dates.num2date(mpldays)\n",
    "\n",
    "    out = Bunch(index_name = index_name, index = index,\n",
    "               ymdhms = ymdhms, mpldaysformated = mpldaysformated)\n",
    "    \n",
    "    return out\n",
    "    #return station_id, rainfall, ymdhms, mpldaysformated\n",
    "\n",
    "def seasonal_anomaly_old(m_anom):\n",
    "    s_anom = np.ma.zeros(m_anom.shape, float)\n",
    "    s_anom[1:-1] = (m_anom[:-2] + m_anom[1:-1] + m_anom[2:]) / 3\n",
    "    s_anom[0] = (m_anom[0] + m_anom[1]) / 2\n",
    "    s_anom[-1] = (m_anom[-2] + m_anom[-1]) / 2\n",
    "    return s_anom\n",
    "\n",
    "def seasonal_sum(m_anom):\n",
    "    s_anom = np.ma.zeros(m_anom.shape, float)\n",
    "    s_anom[1:-1] = (m_anom[:-2] + m_anom[1:-1] + m_anom[2:])\n",
    "    s_anom[0] = (m_anom[0] + m_anom[1])\n",
    "    s_anom[-1] = (m_anom[-2] + m_anom[-1])\n",
    "    return s_anom\n",
    "\n",
    "def running_sum(m_anom, window, nmin = 2):\n",
    "    \n",
    "    if window % 2 == 0:\n",
    "        nmin = (window)/2\n",
    "        #nmin = 1\n",
    "        chop = (window-1)\n",
    "\n",
    "        newshape = [window] + list(m_anom.shape)\n",
    "        newshape[1] += window -1\n",
    "        accum = np.ma.zeros(newshape, dtype=m_anom.dtype)\n",
    "        accum[:] = np.ma.masked\n",
    "        for i in range(window):\n",
    "            end = -window+i+1\n",
    "            if end == 0:\n",
    "                accum[i, i:] = m_anom[:]\n",
    "            else:\n",
    "                accum[i, i:end] = m_anom[:]\n",
    "        if window != 2:\n",
    "            start=window/2\n",
    "            stop = (window/2) -1\n",
    "            out = accum.mean(axis=0)[start:-stop]\n",
    "            out = np.ma.masked_where(accum[:,start:-stop].count(axis=0) < nmin, out, copy=False)\n",
    "        else:\n",
    "            out = accum.mean(axis=0)[1:]\n",
    "            out = np.ma.masked_where(accum[:,1:].count(axis=0) < nmin, out, copy=False)\n",
    "        \n",
    "    else:\n",
    "        nmin = (window+1)/2\n",
    "        chop = (window -1)/2\n",
    "\n",
    "        newshape = [window] + list(m_anom.shape)\n",
    "        newshape[1] += window -1\n",
    "        accum = np.ma.zeros(newshape, dtype=m_anom.dtype)\n",
    "        accum[:] = np.ma.masked\n",
    "        for i in range(window):\n",
    "            end = -window+i+1\n",
    "            if end == 0:\n",
    "                accum[i, i:] = m_anom[:]\n",
    "            else:\n",
    "                accum[i, i:end] = m_anom[:]\n",
    "        out = accum.mean(axis=0)[chop:-chop]\n",
    "        out = np.ma.masked_where(accum[:, chop:-chop].count(axis=0) < nmin, out, copy=False)\n",
    "        \n",
    "    return Bunch(s_anom = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 498.1\n",
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 354.3\n",
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 128.6\n",
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 353.9\n",
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 599.9\n",
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 292.9\n",
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 340.5\n",
      "<class 'numpy.ndarray'> object\n",
      "rainfall:  float64 --\n"
     ]
    }
   ],
   "source": [
    "station_name_list = [\"Koror\", \"Yap\", \"Guam\", \"Chuuk\", \"Pohnpei\", \"Kwajalein\", \"Majuro\", \"Saipan\"]\n",
    "#variable_name_list = [koror, yap, guam, chuuk, phonpei, kwajalein, majuro]\n",
    "\n",
    "stations = Bunch()\n",
    "for name in station_name_list:\n",
    "    stations[name] = read_USAPI_data(peac_station_rain, name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for raindata in stations.values():\n",
    "    #print(raindata.island_name)\n",
    "    #print(np.shape(raindata.rainfall))\n",
    "    raindata.monmean = raindata.rainfall.mean(axis=0)\n",
    "    raindata.monstd = raindata.rainfall.std(axis=0)\n",
    "    raindata.monanom = raindata.rainfall - raindata.monmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/numpy/ma/core.py:3114: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  dout = self.data[indx]\n",
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/numpy/ma/core.py:3169: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  dout._mask = _mask[indx]\n"
     ]
    }
   ],
   "source": [
    "#print(np.shape(stations.Kwajalein.monanom))\n",
    "kwajalein_seasonal_anom = seasonal_anomaly_old(stations.Kwajalein.monanom.ravel())\n",
    "kwajalein_seasonal_total = seasonal_sum(stations.Kwajalein.rainfall.ravel())\n",
    "kwajalein_dry_season_total = running_sum(stations.Kwajalein.rainfall.ravel(),6)\n",
    "kwajalein_dry_season_anom = running_sum(stations.Kwajalein.monanom.ravel(),6)\n",
    "\n",
    "guam_seasonal_anom = seasonal_anomaly_old(stations.Guam.monanom.ravel())\n",
    "guam_seasonal_total = seasonal_sum(stations.Guam.rainfall.ravel())\n",
    "guam_dry_season_total = running_sum(stations.Guam.rainfall.ravel(),6)\n",
    "guam_dry_season_anom = running_sum(stations.Guam.monanom.ravel(),6)\n",
    "\n",
    "\n",
    "yap_seasonal_anom = seasonal_anomaly_old(stations.Yap.monanom.ravel())\n",
    "yap_seasonal_total = seasonal_sum(stations.Yap.rainfall.ravel())\n",
    "yap_dry_season_total = running_sum(stations.Yap.rainfall.ravel(),6)\n",
    "yap_dry_season_anom = running_sum(stations.Yap.monanom.ravel(),6)\n",
    "\n",
    "majuro_seasonal_anom = seasonal_anomaly_old(stations.Majuro.monanom.ravel())\n",
    "majuro_seasonal_total = seasonal_sum(stations.Majuro.rainfall.ravel())\n",
    "majuro_dry_season_total = running_sum(stations.Majuro.rainfall.ravel(),6)\n",
    "majuro_dry_season_anom = running_sum(stations.Majuro.monanom.ravel(),6)\n",
    "\n",
    "chuuk_seasonal_anom = seasonal_anomaly_old(stations.Chuuk.monanom.ravel())\n",
    "chuuk_seasonal_total = seasonal_sum(stations.Chuuk.rainfall.ravel())\n",
    "chuuk_dry_season_total = running_sum(stations.Chuuk.rainfall.ravel(),6)\n",
    "chuuk_dry_season_anom = running_sum(stations.Chuuk.monanom.ravel(),6)\n",
    "\n",
    "koror_seasonal_anom = seasonal_anomaly_old(stations.Koror.monanom.ravel())\n",
    "koror_seasonal_total = seasonal_sum(stations.Koror.rainfall.ravel())\n",
    "koror_dry_season_total = running_sum(stations.Koror.rainfall.ravel(),6)\n",
    "koror_dry_season_anom = running_sum(stations.Koror.monanom.ravel(),6)\n",
    "\n",
    "pohnpei_seasonal_anom = seasonal_anomaly_old(stations.Pohnpei.monanom.ravel())\n",
    "pohnpei_seasonal_total = seasonal_sum(stations.Pohnpei.rainfall.ravel())\n",
    "pohnpei_dry_season_total = running_sum(stations.Pohnpei.rainfall.ravel(),6)\n",
    "pohnpei_dry_season_anom = running_sum(stations.Pohnpei.monanom.ravel(),6)\n",
    "\n",
    "saipan_seasonal_anom = seasonal_anomaly_old(stations.Saipan.monanom.ravel())\n",
    "saipan_seasonal_total = seasonal_sum(stations.Saipan.rainfall.ravel())\n",
    "saipan_dry_season_total = running_sum(stations.Saipan.rainfall.ravel(),6)\n",
    "saipan_dry_season_anom = running_sum(stations.Saipan.monanom.ravel(),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(saipan_dry_season_anom.s_anom.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# window = 6\n",
    "# m_anom = stations.Pohnpei.rainfall.ravel()\n",
    "\n",
    "# nmin = (window)/2\n",
    "# #nmin = 1\n",
    "# chop = (window-1)\n",
    "\n",
    "# newshape = [window] + list(m_anom.shape)\n",
    "# newshape[1] += window -1\n",
    "# accum = np.ma.zeros(newshape, dtype=m_anom.dtype)\n",
    "# accum[:] = np.ma.masked\n",
    "# for i in range(window):\n",
    "#     end = -window+i+1\n",
    "#     if end == 0:\n",
    "#         accum[i, i:] = m_anom[:]\n",
    "#     else:\n",
    "#         accum[i, i:end] = m_anom[:]\n",
    "# if window != 2:\n",
    "#     start=window/2\n",
    "#     stop = (window/2) -1\n",
    "#     out = accum.mean(axis=0)[start:-stop]\n",
    "#     out = np.ma.masked_where(accum[:,start:-stop].count(axis=0) < nmin, out, copy=False)\n",
    "# else:\n",
    "#     out = accum.mean(axis=0)[1:]\n",
    "#     out = np.ma.masked_where(accum[:,1:].count(axis=0) < nmin, out, copy=False)\n",
    "    \n",
    "# print(np.shape(out))\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spi_calculation(data, climatology_series):\n",
    "    \n",
    "    good_data = data[~data.mask]\n",
    "    good_climatology = climatology_series[~climatology_series.mask]\n",
    "    \n",
    "    spi = np.empty_like(good_data)\n",
    "    spi[:] = np.NAN\n",
    "\n",
    "    #fit gamma distribution to climatology series\n",
    "    fit_alpha, fit_loc, fit_beta = stats.gamma.fit(good_climatology)\n",
    "\n",
    "    #find cumulative probabilities of data from fitted distribution\n",
    "    data_cdf = stats.gamma.cdf(good_data, fit_alpha, loc=fit_loc, scale=fit_beta)\n",
    "\n",
    "    # find the percent points from the random normal dist\n",
    "\n",
    "    spi[:] = stats.norm.ppf(data_cdf, loc=0, scale=1)\n",
    "    \n",
    "    return spi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = saipan_dry_season_total.s_anom.reshape(51, 12)[:,1]\n",
    "# climatology_series = saipan_dry_season_total.s_anom.reshape(51, 12)[:,1]\n",
    "\n",
    "# good_data = data[~data.mask]\n",
    "# good_climatology = climatology_series[~climatology_series.mask]\n",
    "\n",
    "# spi = np.empty_like(good_data)\n",
    "# spi[:] = np.NAN\n",
    "\n",
    "# #fit gamma distribution to climatology series\n",
    "# fit_alpha, fit_loc, fit_beta = stats.gamma.fit(good_climatology)\n",
    "\n",
    "# #find cumulative probabilities of data from fitted distribution\n",
    "# data_cdf = stats.gamma.cdf(good_data, fit_alpha, loc=fit_loc, scale=fit_beta)\n",
    "\n",
    "# # find the percent points from the random normal dist\n",
    "\n",
    "# spi[:] = stats.norm.ppf(data_cdf, loc=0, scale=1)\n",
    "\n",
    "# print(np.shape(spi))\n",
    "# print(spi)\n",
    "# print(good_data)\n",
    "# plt.plot(spi)\n",
    "# plt.plot(good_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwajalein_dry_season_total_matrix = kwajalein_dry_season_total.s_anom.reshape(51, 12)\n",
    "kwajalein_dry_season_anom_matrix = kwajalein_dry_season_anom.s_anom.reshape(51, 12)\n",
    "majuro_dry_season_anom_matrix = majuro_dry_season_anom.s_anom.reshape(51, 12)\n",
    "guam_dry_season_anom_matrix = guam_dry_season_anom.s_anom.reshape(51, 12)\n",
    "yap_dry_season_anom_matrix = yap_dry_season_anom.s_anom.reshape(51, 12)\n",
    "koror_dry_season_anom_matrix = koror_dry_season_anom.s_anom.reshape(51, 12)\n",
    "chuuk_dry_season_anom_matrix = chuuk_dry_season_anom.s_anom.reshape(51, 12)\n",
    "pohnpei_dry_season_anom_matrix = pohnpei_dry_season_anom.s_anom.reshape(51, 12)\n",
    "saipan_dry_season_anom_matrix = saipan_dry_season_anom.s_anom.reshape(51, 12)\n",
    "\n",
    "#Put ONI data into a pandas table\n",
    "season_list = ['DJF' , 'JFM' , 'FMA',\n",
    "               'MAM' , 'AMJ' , 'MJJ',\n",
    "               'JJA' , 'JAS' , 'ASO',\n",
    "               'SON' , 'OND' , 'NDJ']\n",
    "\n",
    "seven_month_list = ['Oct-Jan-Apr' , 'Nov-Feb-May' , 'Dec-Mar-Jun',\n",
    "                    'Jan-Apr-Jul' , 'Feb-May-Aug' , 'Mar-Jun-Sep',\n",
    "                    'Apr-Jul-Oct' , 'May-Aug-Nov' , 'Jun-Sep-Dec',\n",
    "                    'Jul-Oct-Jan' , 'Aug-Nov-Feb' , 'Sep-Dec-Mar']   \n",
    "\n",
    "six_month_list = ['Nov-Apr' , 'Dec-May' , 'Jan-Jun',\n",
    "                  'Feb-Jul' , 'Mar-Aug' , 'Apr-Sep',\n",
    "                  'May-Oct' , 'Jun-Nov' , 'Jul-Dec',\n",
    "                  'Aug-Jan' , 'Sep-Feb' , 'Oct-Mar']    \n",
    "\n",
    "kawj_dry_season_total_df = pd.DataFrame(kwajalein_dry_season_total_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "kawj_dry_season_anom_df = pd.DataFrame(kwajalein_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "#kawj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kwajalein_dry_season_total_matrix = kwajalein_dry_season_total.s_anom.reshape(51, 12)\n",
    "\n",
    "kwajalein_spi_matrix = np.empty_like(kwajalein_dry_season_total_matrix)\n",
    "kwajalein_spi_matrix[:] = np.NAN\n",
    "\n",
    "for col in range(kwajalein_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(kwajalein_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(kwajalein_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    kwajalein_spi_matrix[:len(spi),col] = spi\n",
    "    \n",
    "\n",
    "    \n",
    "guam_dry_season_total_matrix = guam_dry_season_total.s_anom.reshape(51, 12)\n",
    "guam_spi_matrix = np.empty_like(guam_dry_season_total_matrix)\n",
    "guam_spi_matrix[:] = np.NAN\n",
    "\n",
    "for col in range(guam_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(guam_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(guam_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    guam_spi_matrix[:len(spi),col] = spi\n",
    "    \n",
    "    \n",
    "yap_dry_season_total_matrix = yap_dry_season_total.s_anom.reshape(51, 12)\n",
    "yap_spi_matrix = np.empty_like(yap_dry_season_total_matrix)\n",
    "yap_spi_matrix[:] = np.NAN\n",
    "\n",
    "for col in range(yap_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(yap_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(yap_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    yap_spi_matrix[:len(spi),col] = spi\n",
    "    \n",
    "majuro_dry_season_total_matrix = majuro_dry_season_total.s_anom.reshape(51, 12)\n",
    "majuro_spi_matrix = np.empty_like(majuro_dry_season_total_matrix)\n",
    "majuro_spi_matrix[:] = np.NAN\n",
    "\n",
    "for col in range(majuro_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(majuro_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(majuro_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    majuro_spi_matrix[:len(spi),col] = spi\n",
    "    \n",
    "    \n",
    "koror_dry_season_total_matrix = koror_dry_season_total.s_anom.reshape(51, 12)\n",
    "koror_spi_matrix = np.empty_like(koror_dry_season_total_matrix)\n",
    "koror_spi_matrix[:] = np.NAN\n",
    "\n",
    "for col in range(koror_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(koror_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(koror_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    koror_spi_matrix[:len(spi),col] = spi\n",
    "    \n",
    "    \n",
    "chuuk_dry_season_total_matrix = chuuk_dry_season_total.s_anom.reshape(51, 12)\n",
    "chuuk_spi_matrix = np.empty_like(chuuk_dry_season_total_matrix)\n",
    "chuuk_spi_matrix[:] = np.NAN\n",
    "\n",
    "for col in range(chuuk_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(chuuk_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(chuuk_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    chuuk_spi_matrix[:len(spi),col] = spi\n",
    "    \n",
    "    \n",
    "pohnpei_dry_season_total_matrix = pohnpei_dry_season_total.s_anom.reshape(51, 12)\n",
    "pohnpei_spi_matrix = np.empty_like(pohnpei_dry_season_total_matrix)\n",
    "pohnpei_spi_matrix[:] = np.NAN\n",
    "\n",
    "for col in range(pohnpei_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(pohnpei_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(pohnpei_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    pohnpei_spi_matrix[:len(spi),col] = spi\n",
    "    \n",
    "saipan_dry_season_total_matrix = saipan_dry_season_total.s_anom.reshape(51, 12)\n",
    "saipan_spi_matrix = np.empty_like(saipan_dry_season_total_matrix)\n",
    "saipan_spi_matrix[:] = np.NAN\n",
    "saipan_spi_matrix_temp = np.empty_like(saipan_dry_season_total_matrix)\n",
    "saipan_spi_matrix_temp[:] = np.NAN\n",
    "\n",
    "for col in range(saipan_dry_season_total_matrix.shape[1]):\n",
    "    #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "    spi = spi_calculation(np.squeeze(saipan_dry_season_total_matrix[:,col]),\n",
    "                          np.squeeze(saipan_dry_season_total_matrix[:,col]))\n",
    "\n",
    "    saipan_spi_matrix_temp[-len(spi):,col] = spi\n",
    "\n",
    "saipan_spi_matrix_temp[saipan_spi_matrix_temp == np.inf] = 7\n",
    "saipan_mask = np.ma.getmask(saipan_dry_season_total_matrix)\n",
    "saipan_spi_matrix = np.ma.masked_invalid(np.ma.array(saipan_spi_matrix_temp,mask = saipan_mask))\n",
    "    \n",
    "#Put ONI data into a pandas table\n",
    "seven_month_list = ['Oct-Jan-Apr' , 'Nov-Feb-May' , 'Dec-Mar-Jun',\n",
    "                    'Jan-Apr-Jul' , 'Feb-May-Aug' , 'Mar-Jun-Sep',\n",
    "                    'Apr-Jul-Oct' , 'May-Aug-Nov' , 'Jun-Sep-Dec',\n",
    "                    'Jul-Oct-Jan' , 'Aug-Nov-Feb' , 'Sep-Dec-Mar']    \n",
    "    \n",
    "six_month_list = ['Nov-Apr' , 'Dec-May' , 'Jan-Jun',\n",
    "                  'Feb-Jul' , 'Mar-Aug' , 'Apr-Sep',\n",
    "                  'May-Oct' , 'Jun-Nov' , 'Jul-Dec',\n",
    "                  'Aug-Jan' , 'Sep-Feb' , 'Oct-Mar']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saipan_spi_matrix[saipan_spi_matrix == np.inf] = 10\n",
    "# saipan_mask = np.ma.getmask(saipan_dry_season_total_matrix)\n",
    "# saipan_spi_matrix_2 = np.ma.masked_invalid(np.ma.array(saipan_spi_matrix,mask = saipan_mask))\n",
    "# print(saipan_dry_season_total_matrix)\n",
    "# print(saipan_spi_matrix_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saipan_dry_season_total_matrix = saipan_dry_season_total.s_anom.reshape(51, 12)[:,1]\n",
    "\n",
    "# good_data = saipan_dry_season_total_matrix[~saipan_dry_season_total_matrix.mask]\n",
    "# good_climatology = saipan_dry_season_total_matrix[~saipan_dry_season_total_matrix.mask]\n",
    "\n",
    "# spi = np.empty_like(good_data)\n",
    "# spi[:] = np.NAN\n",
    "\n",
    "# #fit gamma distribution to climatology series\n",
    "# fit_alpha, fit_loc, fit_beta = stats.gamma.fit(good_climatology)\n",
    "\n",
    "# #find cumulative probabilities of data from fitted distribution\n",
    "# data_cdf = stats.gamma.cdf(good_data, fit_alpha, loc=fit_loc, scale=fit_beta)\n",
    "\n",
    "# # find the percent points from the random normal dist\n",
    "\n",
    "# spi[:] = stats.norm.ppf(data_cdf, loc=0, scale=1)\n",
    "# print(saipan_dry_season_total.s_anom.reshape(51, 12)[:,1])\n",
    "# print(spi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saipan_dry_season_total_matrix = saipan_dry_season_total.s_anom.reshape(51, 12)\n",
    "# saipan_spi_matrix = np.empty_like(saipan_dry_season_total_matrix)\n",
    "# saipan_spi_matrix[:] = np.NAN\n",
    "\n",
    "# for col in range(saipan_dry_season_total_matrix.shape[1]):\n",
    "#     #print(kwajalein_seasonal_total_matrix[:,col])\n",
    "#     spi = spi_calculation(np.squeeze(saipan_dry_season_total_matrix[:,col]),\n",
    "#                           np.squeeze(saipan_dry_season_total_matrix[:,col]))\n",
    "\n",
    "#     saipan_spi_matrix[-len(spi):,col] = spi\n",
    "#     #test[:len(spi),col] = spi\n",
    "    \n",
    "# #print(np.ma.masked_invalid(saipan_spi_matrix))\n",
    "# print(saipan_dry_season_total_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def spi_d_category_cells_dry(data):\n",
    "    \n",
    "    if -0.5 >= data > -0.8:\n",
    "        color = 'yellow'\n",
    "    elif -0.8 >= data > -1.3:\n",
    "        color = 'sandybrown'\n",
    "    elif -1.3 >= data > -1.5:\n",
    "        color = 'darkorange'\n",
    "    elif -1.5 >= data > -1.9:\n",
    "        color = 'red'\n",
    "    elif -2 >= data:\n",
    "        color = 'darkred'\n",
    "    else:\n",
    "        color = ''\n",
    "        #attr = 'background-color: {}'.format('yellow')\n",
    "    return 'background-color: %s' %color\n",
    "\n",
    "def spi_d_category_cells_wet(data):\n",
    "    \n",
    "    if 0.5 <= data:\n",
    "        color = 'skyblue'\n",
    "    else:\n",
    "        color = ''\n",
    "        #attr = 'background-color: {}'.format('yellow')\n",
    "    return 'background-color: %s' %color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kwajalein_SPI_df = pd.DataFrame(kwajalein_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "majuro_SPI_df = pd.DataFrame(majuro_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "guam_SPI_df = pd.DataFrame(guam_spi_matrix, columns = six_month_list, index = range(1966,2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saipan_SPI_df = pd.DataFrame(saipan_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "saip_dry_season_anom_df = pd.DataFrame(saipan_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "#saipan_SPI_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float64\n",
      "index:  float64 -0.6\n"
     ]
    }
   ],
   "source": [
    "oni = read_index_data(ONI_file, \"ONI\")\n",
    "oni_selection = ((oni.ymdhms[:, 0] >= 1966))\n",
    "oni_time_series = oni.index.ravel()\n",
    "oni_period = oni_time_series[oni_selection]\n",
    "oni_period_matrix = oni_period.reshape(51,12)\n",
    "ONI_df = pd.DataFrame(oni_period_matrix, columns = season_list, index = range(1966,2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the agreggate drought for \n",
    "## Kwajalein, Majuro, Yap and Guam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First using the average SPI for the 4 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_spi_matrix = np.mean(np.array([kwajalein_spi_matrix, majuro_spi_matrix, guam_spi_matrix, yap_spi_matrix]), axis=0)\n",
    "\n",
    "\n",
    "average_dry_season_anom_matrix = np.mean(np.array([kwajalein_dry_season_anom_matrix, \n",
    "                                                   majuro_dry_season_anom_matrix, \n",
    "                                                   guam_dry_season_anom_matrix, \n",
    "                                                   yap_dry_season_anom_matrix]), axis=0)\n",
    "\n",
    "average_all_station_spi_matrix = np.mean(np.array([kwajalein_spi_matrix, \n",
    "                                                   majuro_spi_matrix, \n",
    "                                                   guam_spi_matrix, \n",
    "                                                   yap_spi_matrix,\n",
    "                                                   chuuk_spi_matrix,\n",
    "                                                   koror_spi_matrix,\n",
    "                                                   pohnpei_spi_matrix]), axis=0)\n",
    "\n",
    "\n",
    "average_all_station_dry_season_anom_matrix = np.mean(np.array([kwajalein_dry_season_anom_matrix, \n",
    "                                                               majuro_dry_season_anom_matrix, \n",
    "                                                               guam_dry_season_anom_matrix, \n",
    "                                                               yap_dry_season_anom_matrix,\n",
    "                                                               chuuk_dry_season_anom_matrix, \n",
    "                                                               koror_dry_season_anom_matrix, \n",
    "                                                               pohnpei_dry_season_anom_matrix,]), axis=0)\n",
    "\n",
    "average_6_station_spi_matrix = np.mean(np.array([kwajalein_spi_matrix, \n",
    "                                                   majuro_spi_matrix, \n",
    "                                                   guam_spi_matrix, \n",
    "                                                   yap_spi_matrix,\n",
    "                                                   pohnpei_spi_matrix,\n",
    "                                                   koror_spi_matrix]), axis=0)\n",
    "\n",
    "\n",
    "average_6_station_dry_season_anom_matrix = np.mean(np.array([kwajalein_dry_season_anom_matrix, \n",
    "                                                               majuro_dry_season_anom_matrix, \n",
    "                                                               guam_dry_season_anom_matrix, \n",
    "                                                               yap_dry_season_anom_matrix,\n",
    "                                                               pohnpei_dry_season_anom_matrix, \n",
    "                                                               koror_dry_season_anom_matrix,]), axis=0)\n",
    "\n",
    "average_5_station_spi_matrix = np.mean(np.array([kwajalein_spi_matrix, \n",
    "                                                   majuro_spi_matrix, \n",
    "                                                   guam_spi_matrix, \n",
    "                                                   yap_spi_matrix,\n",
    "                                                   chuuk_spi_matrix]), axis=0)\n",
    "\n",
    "\n",
    "average_5_station_dry_season_anom_matrix = np.mean(np.array([kwajalein_dry_season_anom_matrix, \n",
    "                                                               majuro_dry_season_anom_matrix, \n",
    "                                                               guam_dry_season_anom_matrix, \n",
    "                                                               yap_dry_season_anom_matrix,\n",
    "                                                               chuuk_dry_season_anom_matrix]), axis=0)\n",
    "\n",
    "average_3_station_spi_matrix = np.mean(np.array([kwajalein_spi_matrix, \n",
    "                                                   guam_spi_matrix, \n",
    "                                                   yap_spi_matrix]), axis=0)\n",
    "\n",
    "\n",
    "average_3_station_dry_season_anom_matrix = np.mean(np.array([kwajalein_dry_season_anom_matrix, \n",
    "                                                               guam_dry_season_anom_matrix, \n",
    "                                                               yap_dry_season_anom_matrix]), axis=0)\n",
    "\n",
    "average_2_station_spi_matrix = np.mean(np.array([kwajalein_spi_matrix, \n",
    "                                                   guam_spi_matrix]), axis=0)\n",
    "\n",
    "\n",
    "average_2_station_dry_season_anom_matrix = np.mean(np.array([kwajalein_dry_season_anom_matrix, \n",
    "                                                               guam_dry_season_anom_matrix]), axis=0)\n",
    "\n",
    "average_3_saip_station_spi_matrix = np.nanmean(np.array([kwajalein_spi_matrix,\n",
    "                                                      saipan_spi_matrix,\n",
    "                                                      guam_spi_matrix]), axis=0)\n",
    "\n",
    "\n",
    "average_3_saip_station_dry_season_anom_matrix = np.nanmean(np.array([kwajalein_dry_season_anom_matrix,\n",
    "                                                                     saipan_dry_season_anom_matrix,\n",
    "                                                                     guam_dry_season_anom_matrix]), axis=0)\n",
    "\n",
    "average_SPI_df = pd.DataFrame(average_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "average_dry_season_anom_df = pd.DataFrame(average_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "\n",
    "average_all_station_SPI_df = pd.DataFrame(average_all_station_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "average_all_station_dry_season_anom_df = pd.DataFrame(average_all_station_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "\n",
    "average_6_station_SPI_df = pd.DataFrame(average_6_station_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "average_6_station_dry_season_anom_df = pd.DataFrame(average_6_station_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "\n",
    "average_5_station_SPI_df = pd.DataFrame(average_5_station_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "average_5_station_dry_season_anom_df = pd.DataFrame(average_5_station_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "\n",
    "average_3_station_SPI_df = pd.DataFrame(average_3_station_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "average_3_station_dry_season_anom_df = pd.DataFrame(average_3_station_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "\n",
    "average_2_station_SPI_df = pd.DataFrame(average_2_station_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "average_2_station_dry_season_anom_df = pd.DataFrame(average_2_station_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "\n",
    "average_3_saip_station_SPI_df = pd.DataFrame(average_3_saip_station_spi_matrix, columns = six_month_list, index = range(1966,2017))\n",
    "average_3_saip_station_dry_season_anom_df = pd.DataFrame(average_3_saip_station_dry_season_anom_matrix, columns = six_month_list, index = range(1966,2017))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 12)\n",
      "[0 0 1 0 1 1 2]\n",
      "[[ 146.41011765  113.43419608  116.57205229  143.59424837  184.69294118\n",
      "   236.18760784  315.91762667  354.27481333  336.5306      310.58204\n",
      "   240.06989333  192.74466333]\n",
      " [ 232.78579085  199.32577778  219.1208366   270.04049673  298.55929412\n",
      "   343.23721569  358.93702667  333.48104     319.41770667  327.40458667\n",
      "   298.14862667  294.5678    ]\n",
      " [ 304.41062745  256.22133333  360.9854902   436.92576471  494.87407843\n",
      "   423.47772549  425.68704     395.9138      381.44144     392.94344\n",
      "   388.62536     386.81464   ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kwaj = stations.Kwajalein.monmean\n",
    "guam = stations.Guam.monmean\n",
    "majuro = stations.Majuro.monmean\n",
    "yap = stations.Yap.monmean\n",
    "koror = stations.Koror.monmean\n",
    "chuuk = stations.Chuuk.monmean\n",
    "pohnpei = stations.Pohnpei.monmean\n",
    "\n",
    "stations_mon_means = np.array([kwaj, guam, majuro, yap, koror, chuuk, pohnpei])\n",
    "\n",
    "print(np.shape(stations_mon_means))\n",
    "\n",
    "s_kmeans = KMeans(n_clusters=3).fit(stations_mon_means)\n",
    "print(s_kmeans.labels_)\n",
    "print(s_kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# six_month_list = ['Nov-Apr' , 'Dec-May' , 'Jan-Jun',\n",
    "#                   'Feb-Jul' , 'Mar-Aug' , 'Apr-Sep',\n",
    "#                   'May-Oct' , 'Jun-Nov' , 'Jul-Dec',\n",
    "#                   'Aug-Jan' , 'Sep-Feb' , 'Oct-Mar']  \n",
    "\n",
    "oni_selection = (np.logical_and((oni.ymdhms[:, 0] >= 1966), (oni.ymdhms[:, 1]== 2)))\n",
    "ymdhms_dates = oni.ymdhms[oni_selection]\n",
    "\n",
    "mpl_dates = np.empty(len(ymdhms_dates), dtype='datetime64[M]')\n",
    "\n",
    "for i, ymdhms in enumerate(ymdhms_dates):\n",
    "    date = ymdhms_dates[i]\n",
    "    mpl_dates[i] = datetime.date(date[0],date[1],date[2])\n",
    "\n",
    "\n",
    "varlist = [saip_dry_season_anom_df['Dec-May'], \n",
    "           saipan_SPI_df['Dec-May'], \n",
    "           average_3_saip_station_dry_season_anom_df['Dec-May'], \n",
    "           average_3_saip_station_SPI_df['Dec-May']]\n",
    "varlist_2 = [saipan_SPI_df['Dec-May'], \n",
    "             ONI_df['DJF'], \n",
    "             average_3_station_SPI_df['Dec-May'], \n",
    "             ONI_df['DJF']]\n",
    "plot_titles = ['Saipan Dry Season Rainfall Anom and Dry Season SPI',\n",
    "              'Saipan Dry Season SPI and ONI',\n",
    "              'Yap, Guam and Kwaj, Dry Season Rainfall Anom and Dry Season SPI',\n",
    "              'Yap, Guam and Kwaj, Dry Season SPI and ONI']\n",
    "ylab = ['(mm/month)', 'SPI', '(mm/month)', 'SPI']\n",
    "ylab_2 = ['SPI', 'ONI (C)', 'SPI', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(6.5, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for var, var2, tit, ax, y, y2 in zip(varlist,varlist_2, plot_titles, axs, ylab, ylab_2):\n",
    "    cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit+cor, fontsize = 8)\n",
    "    lines = ax.plot(mpl_dates, var, 'b-')\n",
    "    ax.set_ylabel(y, color='b')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    ax_max = np.amax(var)\n",
    "    ax_min = np.amin(var)\n",
    "    ax_tot_max = np.maximum(ax_max, np.absolute(ax_min))\n",
    "    ax.set_ylim([-ax_tot_max,ax_tot_max])\n",
    "    \n",
    "    ax_e = ax.twinx()\n",
    "    line_2 = ax_e.plot(mpl_dates, var2, 'r-')\n",
    "    ax_e.set_ylabel(y2, color='r')\n",
    "    \n",
    "    ax_max = np.amax(var2)\n",
    "    ax_min = np.amin(var2)\n",
    "    ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "    ax_e.set_ylim([-ax_tot_max2,ax_tot_max2])\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "    #lines_list.append(lines)\n",
    "fig.savefig('saipan_time_series.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "varlist = [average_SPI_df.loc[1979:]['Dec-May'],  \n",
    "           average_3_station_SPI_df.loc[1979:]['Dec-May']]\n",
    "varlist_2 = [ONI_df.loc[1979:]['DJF'], \n",
    "             ONI_df.loc[1979:]['DJF']]\n",
    "plot_titles = ['Yap, Guam, Maj and Kwaj, Avg Dry Season SPI vs ONI',\n",
    "               'Yap, Guam and Kwaj Avg Dry Season SPI vs ONI']\n",
    "ylab = ['SPI', 'SPI']\n",
    "xlab = ['ONI (C)', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(12, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for yvar, xvar, tit, ax, y, x in zip(varlist,varlist_2, plot_titles, axs, ylab, xlab):\n",
    "    #cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit, fontsize = 12)\n",
    "    scatter = ax.scatter(xvar, yvar, c='k', label = '1979-2016')\n",
    "    ax.set_ylabel(y, color='k')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_xlabel(x, color='k')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    year_list = [ 1984, 2001, 2006, 2009, 2013]\n",
    "    dry_y = np.empty(len(year_list))\n",
    "    dry_x = np.empty(len(year_list))\n",
    "    non_dry_year_list = [1985, 1986, 1996, 1997, 2014]\n",
    "    non_dry_y = np.empty(len(non_dry_year_list))\n",
    "    non_dry_x = np.empty(len(non_dry_year_list))\n",
    "    la_nina_list =  [1989, 1999, 2000, 2008, 2011]\n",
    "    lanina_y = np.empty(len(la_nina_list))\n",
    "    lanina_x = np.empty(len(la_nina_list))\n",
    "    \n",
    "    for year in range(1979,2017):\n",
    "        \n",
    "        if year in year_list:\n",
    "            i = year_list.index(year)\n",
    "            dry_y[i] = yvar[year]\n",
    "            dry_x[i] = xvar[year]\n",
    "            #scatter = ax.scatter(xvar[year], yvar[year], c='r', label = 'Members of Dry Composite')\n",
    "         \n",
    "        elif year in la_nina_list:\n",
    "            i = la_nina_list.index(year)\n",
    "            lanina_y[i] = yvar[year]\n",
    "            lanina_x[i] = xvar[year]\n",
    "            \n",
    "        elif year in non_dry_year_list:\n",
    "            i = non_dry_year_list.index(year)\n",
    "            non_dry_y[i] = yvar[year]\n",
    "            non_dry_x[i] = xvar[year]\n",
    "            \n",
    "    scatter = ax.scatter(dry_x, dry_y, c='r', label = 'Members of Dry Composite')\n",
    "    scatter = ax.scatter(non_dry_x, non_dry_y, c='deepskyblue', label = 'Members of Non Dry Composite')\n",
    "    scatter = ax.scatter(lanina_x, lanina_y, c='b', label = 'Members of La Nina Composite')\n",
    "    \n",
    "    plt.legend(loc='upper center')\n",
    "    \n",
    "    ax_max = np.amax(xvar)\n",
    "    ax_min = np.amin(xvar)\n",
    "    ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "    \n",
    "    if y == 'SPI':\n",
    "        ax.set_ylim([-2,2])\n",
    "    else:\n",
    "        ax_max = np.amax(yvar)\n",
    "        ax_min = np.amin(yvar)\n",
    "        ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "        ax.set_ylim([-ax_tot_max2-10,ax_tot_max2+10])\n",
    "        \n",
    "    #if ax ==1:\n",
    "\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "\n",
    "#plt.legend(bbox_to_anchor = (0,0),loc = 'upper left',borderaxespad =0.)\n",
    "\n",
    "plt.legend()\n",
    "    \n",
    "fig.savefig('scatterplots_YGMK_SPI_v_YGK_SPI.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varlist = [average_SPI_df.loc[1979:]['Dec-May'],  \n",
    "           average_3_station_SPI_df.loc[1979:]['Dec-May']]\n",
    "varlist_2 = [ONI_df.loc[1979:]['DJF'], \n",
    "             ONI_df.loc[1979:]['DJF']]\n",
    "plot_titles = ['Yap, Guam, Maj and Kwaj, Avg Dry Season SPI vs ONI',\n",
    "               'Yap, Guam and Kwaj Avg Dry Season SPI vs ONI']\n",
    "ylab = ['SPI', 'SPI']\n",
    "xlab = ['ONI (C)', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(12, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for yvar, xvar, tit, ax, y, x in zip(varlist,varlist_2, plot_titles, axs, ylab, xlab):\n",
    "    #cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit, fontsize = 12)\n",
    "    scatter = ax.scatter(xvar, yvar, c='k', label = '1979-2016')\n",
    "    ax.set_ylabel(y, color='k')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_xlabel(x, color='k')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    year_list = [ 1984, 2001, 2006, 2009, 2013]\n",
    "    dry_y = np.empty(len(year_list))\n",
    "    dry_x = np.empty(len(year_list))\n",
    "    non_dry_year_list = [1985, 1986, 1996, 1997, 2014]\n",
    "    non_dry_y = np.empty(len(non_dry_year_list))\n",
    "    non_dry_x = np.empty(len(non_dry_year_list))\n",
    "    la_nina_list =  [1989, 1999, 2000, 2008, 2011]\n",
    "    lanina_y = np.empty(len(la_nina_list))\n",
    "    lanina_x = np.empty(len(la_nina_list))\n",
    "    \n",
    "    for year in range(1979,2017):\n",
    "        \n",
    "        if year in year_list:\n",
    "            i = year_list.index(year)\n",
    "            dry_y[i] = yvar[year]\n",
    "            dry_x[i] = xvar[year]\n",
    "            #scatter = ax.scatter(xvar[year], yvar[year], c='r', label = 'Members of Dry Composite')\n",
    "         \n",
    "        elif year in la_nina_list:\n",
    "            i = la_nina_list.index(year)\n",
    "            lanina_y[i] = yvar[year]\n",
    "            lanina_x[i] = xvar[year]\n",
    "            \n",
    "        elif year in non_dry_year_list:\n",
    "            i = non_dry_year_list.index(year)\n",
    "            non_dry_y[i] = yvar[year]\n",
    "            non_dry_x[i] = xvar[year]\n",
    "            \n",
    "    scatter = ax.scatter(dry_x, dry_y, c='r', label = 'Members of Dry Composite')\n",
    "    scatter = ax.scatter(non_dry_x, non_dry_y, c='deepskyblue', label = 'Members of Non Dry Composite')\n",
    "    scatter = ax.scatter(lanina_x, lanina_y, c='b', label = 'Members of La Nina Composite')\n",
    "    \n",
    "    plt.legend(loc='upper center')\n",
    "    \n",
    "    ax_max = np.amax(xvar)\n",
    "    ax_min = np.amin(xvar)\n",
    "    ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "    \n",
    "    if y == 'SPI':\n",
    "        ax.set_ylim([-2,2])\n",
    "    else:\n",
    "        ax_max = np.amax(yvar)\n",
    "        ax_min = np.amin(yvar)\n",
    "        ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "        ax.set_ylim([-ax_tot_max2-10,ax_tot_max2+10])\n",
    "        \n",
    "    #if ax ==1:\n",
    "\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "\n",
    "#plt.legend(bbox_to_anchor = (0,0),loc = 'upper left',borderaxespad =0.)\n",
    "\n",
    "plt.legend()\n",
    "    \n",
    "fig.savefig('scatterplots_YGMK_SPI_v_YGK_SPI.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "varlist = [average_2_station_SPI_df.loc[1979:]['Dec-May'],  \n",
    "           average_all_station_SPI_df.loc[1979:]['Dec-May']]\n",
    "varlist_2 = [ONI_df.loc[1979:]['DJF'], \n",
    "             ONI_df.loc[1979:]['DJF']]\n",
    "plot_titles = ['Guam and Kwaj, Avg Dry Season SPI vs ONI',\n",
    "               'All Station Avg Dry Season SPI vs ONI']\n",
    "ylab = ['SPI', 'SPI']\n",
    "xlab = ['ONI (C)', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(12, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for yvar, xvar, tit, ax, y, x in zip(varlist,varlist_2, plot_titles, axs, ylab, xlab):\n",
    "    #cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit, fontsize = 12)\n",
    "    scatter = ax.scatter(xvar, yvar, c='k', label = '1979-2016')\n",
    "    ax.set_ylabel(y, color='k')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_xlabel(x, color='k')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    year_list = [ 1984, 2001, 2006, 2009, 2013]\n",
    "    dry_y = np.empty(len(year_list))\n",
    "    dry_x = np.empty(len(year_list))\n",
    "    non_dry_year_list = [1985, 1986, 1996, 1997, 2014]\n",
    "    non_dry_y = np.empty(len(non_dry_year_list))\n",
    "    non_dry_x = np.empty(len(non_dry_year_list))\n",
    "    la_nina_list =  [1989, 1999, 2000, 2008, 2011]\n",
    "    lanina_y = np.empty(len(la_nina_list))\n",
    "    lanina_x = np.empty(len(la_nina_list))\n",
    "    \n",
    "    for year in range(1979,2017):\n",
    "        \n",
    "        if year in year_list:\n",
    "            i = year_list.index(year)\n",
    "            dry_y[i] = yvar[year]\n",
    "            dry_x[i] = xvar[year]\n",
    "            #scatter = ax.scatter(xvar[year], yvar[year], c='r', label = 'Members of Dry Composite')\n",
    "         \n",
    "        elif year in la_nina_list:\n",
    "            i = la_nina_list.index(year)\n",
    "            lanina_y[i] = yvar[year]\n",
    "            lanina_x[i] = xvar[year]\n",
    "            \n",
    "        elif year in non_dry_year_list:\n",
    "            i = non_dry_year_list.index(year)\n",
    "            non_dry_y[i] = yvar[year]\n",
    "            non_dry_x[i] = xvar[year]\n",
    "            \n",
    "    scatter = ax.scatter(dry_x, dry_y, c='r', label = 'Members of Dry Composite')\n",
    "    scatter = ax.scatter(non_dry_x, non_dry_y, c='deepskyblue', label = 'Members of Non Dry Composite')\n",
    "    scatter = ax.scatter(lanina_x, lanina_y, c='b', label = 'Members of La Nina Composite')\n",
    "    \n",
    "    plt.legend(loc='upper center')\n",
    "    \n",
    "    ax_max = np.amax(xvar)\n",
    "    ax_min = np.amin(xvar)\n",
    "    ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "    \n",
    "    if y == 'SPI':\n",
    "        ax.set_ylim([-2,2])\n",
    "    else:\n",
    "        ax_max = np.amax(yvar)\n",
    "        ax_min = np.amin(yvar)\n",
    "        ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "        ax.set_ylim([-ax_tot_max2-10,ax_tot_max2+10])\n",
    "        \n",
    "    #if ax ==1:\n",
    "\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "\n",
    "#plt.legend(bbox_to_anchor = (0,0),loc = 'upper left',borderaxespad =0.)\n",
    "\n",
    "plt.legend()\n",
    "    \n",
    "fig.savefig('scatterplots_GK_SPI_v_ALL_SPI.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "varlist = [average_2_station_SPI_df.loc[1979:]['Dec-May'],  \n",
    "           average_3_saip_station_SPI_df.loc[1979:]['Dec-May']]\n",
    "varlist_2 = [ONI_df.loc[1979:]['DJF'], \n",
    "             ONI_df.loc[1979:]['DJF']]\n",
    "plot_titles = ['Guam, and Kwaj, Avg Dry Season SPI vs ONI',\n",
    "               'Guam, Kwaj ans Saip Avg Dry Season SPI vs ONI']\n",
    "ylab = ['SPI', 'SPI']\n",
    "xlab = ['ONI (C)', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(12, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for yvar, xvar, tit, ax, y, x in zip(varlist,varlist_2, plot_titles, axs, ylab, xlab):\n",
    "    #cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit, fontsize = 12)\n",
    "    scatter = ax.scatter(xvar, yvar, c='k', label = '1979-2016')\n",
    "    ax.set_ylabel(y, color='k')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_xlabel(x, color='k')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    year_list = [ 1984, 2001, 2006, 2009, 2013]\n",
    "    dry_y = np.empty(len(year_list))\n",
    "    dry_x = np.empty(len(year_list))\n",
    "    non_dry_year_list = [1985, 1986, 1996, 1997, 2014]\n",
    "    non_dry_y = np.empty(len(non_dry_year_list))\n",
    "    non_dry_x = np.empty(len(non_dry_year_list))\n",
    "    la_nina_list =  [1989, 1999, 2000, 2008, 2011]\n",
    "    lanina_y = np.empty(len(la_nina_list))\n",
    "    lanina_x = np.empty(len(la_nina_list))\n",
    "    \n",
    "    for year in range(1979,2017):\n",
    "        \n",
    "        if year in year_list:\n",
    "            i = year_list.index(year)\n",
    "            dry_y[i] = yvar[year]\n",
    "            dry_x[i] = xvar[year]\n",
    "            #scatter = ax.scatter(xvar[year], yvar[year], c='r', label = 'Members of Dry Composite')\n",
    "         \n",
    "        elif year in la_nina_list:\n",
    "            i = la_nina_list.index(year)\n",
    "            lanina_y[i] = yvar[year]\n",
    "            lanina_x[i] = xvar[year]\n",
    "            \n",
    "        elif year in non_dry_year_list:\n",
    "            i = non_dry_year_list.index(year)\n",
    "            non_dry_y[i] = yvar[year]\n",
    "            non_dry_x[i] = xvar[year]\n",
    "            \n",
    "    scatter = ax.scatter(dry_x, dry_y, c='r', label = 'Members of Dry Composite')\n",
    "    scatter = ax.scatter(non_dry_x, non_dry_y, c='deepskyblue', label = 'Members of Non Dry Composite')\n",
    "    scatter = ax.scatter(lanina_x, lanina_y, c='b', label = 'Members of La Nina Composite')\n",
    "    \n",
    "    plt.legend(loc='upper center')\n",
    "    \n",
    "    ax_max = np.amax(xvar)\n",
    "    ax_min = np.amin(xvar)\n",
    "    ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "    \n",
    "    if y == 'SPI':\n",
    "        ax.set_ylim([-2,2])\n",
    "    else:\n",
    "        ax_max = np.amax(yvar)\n",
    "        ax_min = np.amin(yvar)\n",
    "        ax_tot_max2 = np.maximum(ax_max, np.absolute(ax_min))\n",
    "        ax.set_ylim([-ax_tot_max2-10,ax_tot_max2+10])\n",
    "        \n",
    "    year_labs = [str(x) for x in list(np.arange(1979,2017))]\n",
    "    \n",
    "    for year, x, y in zip(year_labs, xvar, yvar):\n",
    "        ax.annotate(year,xy=(x,y), xytext = (-20,0),\n",
    "                   textcoords = 'offset points',\n",
    "                   #textcoords = 'figure fraction', \n",
    "                   ha = 'right', va='bottom', fontsize = 10,\n",
    "                   arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "\n",
    "#plt.legend(bbox_to_anchor = (0,0),loc = 'upper left',borderaxespad =0.)\n",
    "\n",
    "plt.legend()\n",
    "    \n",
    "fig.savefig('scatterplots_GK_SPI_v_GKS_SPI_labs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "# seven_month_list = ['Oct-Jan-Apr' , 'Nov-Feb-May' , 'Dec-Mar-Jun',\n",
    "#                     'Jan-Apr-Jul' , 'Feb-May-Aug' , 'Mar-Jun-Sep',\n",
    "#                     'Apr-Jul-Oct' , 'May-Aug-Nov' , 'Jun-Sep-Dec',\n",
    "#                     'Jul-Oct-Jan' , 'Aug-Nov-Feb' , 'Sep-Dec-Mar']    \n",
    "\n",
    "\n",
    "varlist = [average_3_station_SPI_df.loc[1979:]['Dec-May'],  \n",
    "           average_2_station_SPI_df.loc[1979:]['Dec-May']]\n",
    "varlist_2 = [ONI_df.loc[1979:]['DJF'], \n",
    "             ONI_df.loc[1979:]['DJF']]\n",
    "plot_titles = ['Yap, Guam, and Kwaj, Avg Dry Season SPI vs ONI',\n",
    "               'Guam and Kwaj Avg Dry Season SPI vs ONI']\n",
    "ylab = ['SPI', 'SPI']\n",
    "xlab = ['ONI (C)', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(12, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for yvar, xvar, tit, ax, y, x in zip(varlist,varlist_2, plot_titles, axs, ylab, xlab):\n",
    "    #cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit, fontsize = 12)\n",
    "    scatter = ax.scatter(xvar, yvar, c='k', label = '1966-2016')\n",
    "    ax.set_ylabel(y, color='k')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_xlabel(x, color='k')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    year_list = [ 1984, 2001, 2006, 2009, 2013]\n",
    "    dry_y = np.empty(len(year_list))\n",
    "    dry_x = np.empty(len(year_list))\n",
    "    non_dry_year_list = [1985, 1986, 1996, 1997, 2014]\n",
    "    non_dry_y = np.empty(len(non_dry_year_list))\n",
    "    non_dry_x = np.empty(len(non_dry_year_list))\n",
    "    \n",
    "    la_nina_list =  [1989, 1999, 2000, 2008, 2011]\n",
    "    lanina_y = np.empty(len(la_nina_list))\n",
    "    lanina_x = np.empty(len(la_nina_list))\n",
    "    \n",
    "    for year in range(1966,2017):\n",
    "        \n",
    "        if year in year_list:\n",
    "            i = year_list.index(year)\n",
    "            dry_y[i] = yvar[year]\n",
    "            dry_x[i] = xvar[year]\n",
    "            #scatter = ax.scatter(xvar[year], yvar[year], c='r', label = 'Members of Dry Composite')\n",
    "         \n",
    "        elif year in la_nina_list:\n",
    "            i = la_nina_list.index(year)\n",
    "            lanina_y[i] = yvar[year]\n",
    "            lanina_x[i] = xvar[year]\n",
    "            \n",
    "        elif year in non_dry_year_list:\n",
    "            i = non_dry_year_list.index(year)\n",
    "            non_dry_y[i] = yvar[year]\n",
    "            non_dry_x[i] = xvar[year]\n",
    "            \n",
    "    scatter = ax.scatter(dry_x, dry_y, c='r', label = 'Members of Dry Composite')\n",
    "    scatter = ax.scatter(non_dry_x, non_dry_y, c='deepskyblue', label = 'Members of Non Dry Composite')\n",
    "    scatter = ax.scatter(lanina_x, lanina_y, c='b', label = 'Members of La Nina Composite')\n",
    "    \n",
    "    year_labs = [str(x) for x in list(np.arange(1979,2017))]\n",
    "    \n",
    "    for year, x, y in zip(year_labs, xvar, yvar):\n",
    "        ax.annotate(year,xy=(x,y), xytext = (-20,0),\n",
    "                   textcoords = 'offset points',\n",
    "                   #textcoords = 'figure fraction', \n",
    "                   ha = 'right', va='bottom', fontsize = 10,\n",
    "                   arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    ax.set_ylim([-3,3])\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "fig.savefig('scatterplots_3_station_SPI_v_2_station_SPI_labs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "# seven_month_list = ['Oct-Jan-Apr' , 'Nov-Feb-May' , 'Dec-Mar-Jun',\n",
    "#                     'Jan-Apr-Jul' , 'Feb-May-Aug' , 'Mar-Jun-Sep',\n",
    "#                     'Apr-Jul-Oct' , 'May-Aug-Nov' , 'Jun-Sep-Dec',\n",
    "#                     'Jul-Oct-Jan' , 'Aug-Nov-Feb' , 'Sep-Dec-Mar']    \n",
    "\n",
    "\n",
    "varlist = [average_3_station_SPI_df.loc[1979:]['Dec-May'],  \n",
    "           average_3_saip_station_SPI_df.loc[1979:]['Dec-May']]\n",
    "varlist_2 = [ONI_df.loc[1979:]['DJF'], \n",
    "             ONI_df.loc[1979:]['DJF']]\n",
    "plot_titles = ['Yap, Guam, and Kwaj, Avg Dry Season SPI vs ONI',\n",
    "               'Guam, Saip, and Kwaj Avg Dry Season SPI vs ONI']\n",
    "ylab = ['SPI', 'SPI']\n",
    "xlab = ['ONI (C)', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(12, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for yvar, xvar, tit, ax, y, x in zip(varlist,varlist_2, plot_titles, axs, ylab, xlab):\n",
    "    #cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit, fontsize = 12)\n",
    "    scatter = ax.scatter(xvar, yvar, c='k', label = '1966-2016')\n",
    "    ax.set_ylabel(y, color='k')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_xlabel(x, color='k')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    year_list = [ 1984, 2001, 2006, 2009, 2013]\n",
    "    dry_y = np.empty(len(year_list))\n",
    "    dry_x = np.empty(len(year_list))\n",
    "    non_dry_year_list = [1985, 1986, 1996, 1997, 2014]\n",
    "    non_dry_y = np.empty(len(non_dry_year_list))\n",
    "    non_dry_x = np.empty(len(non_dry_year_list))\n",
    "    \n",
    "    la_nina_list =  [1989, 1999, 2000, 2008, 2011]\n",
    "    lanina_y = np.empty(len(la_nina_list))\n",
    "    lanina_x = np.empty(len(la_nina_list))\n",
    "    \n",
    "    for year in range(1966,2017):\n",
    "        \n",
    "        if year in year_list:\n",
    "            i = year_list.index(year)\n",
    "            dry_y[i] = yvar[year]\n",
    "            dry_x[i] = xvar[year]\n",
    "            #scatter = ax.scatter(xvar[year], yvar[year], c='r', label = 'Members of Dry Composite')\n",
    "         \n",
    "        elif year in la_nina_list:\n",
    "            i = la_nina_list.index(year)\n",
    "            lanina_y[i] = yvar[year]\n",
    "            lanina_x[i] = xvar[year]\n",
    "            \n",
    "        elif year in non_dry_year_list:\n",
    "            i = non_dry_year_list.index(year)\n",
    "            non_dry_y[i] = yvar[year]\n",
    "            non_dry_x[i] = xvar[year]\n",
    "            \n",
    "    scatter = ax.scatter(dry_x, dry_y, c='r', label = 'Members of Dry Composite')\n",
    "    scatter = ax.scatter(non_dry_x, non_dry_y, c='deepskyblue', label = 'Members of Non Dry Composite')\n",
    "    scatter = ax.scatter(lanina_x, lanina_y, c='b', label = 'Members of La Nina Composite')\n",
    "    \n",
    "    year_labs = [str(x) for x in list(np.arange(1979,2017))]\n",
    "    \n",
    "    for year, x, y in zip(year_labs, xvar, yvar):\n",
    "        ax.annotate(year,xy=(x,y), xytext = (-20,0),\n",
    "                   textcoords = 'offset points',\n",
    "                   #textcoords = 'figure fraction', \n",
    "                   ha = 'right', va='bottom', fontsize = 10,\n",
    "                   arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    ax.set_ylim([-3,3])\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "fig.savefig('scatterplots_KGY_station_SPI_v_3_KGS_station_SPI_labs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "varlist = [average_3_station_SPI_df.loc[1979:]['Dec-May'],  \n",
    "           average_3_saip_station_SPI_df.loc[1979:]['Dec-May']]\n",
    "varlist_2 = [ONI_df.loc[1979:]['DJF'], \n",
    "             ONI_df.loc[1979:]['DJF']]\n",
    "plot_titles = ['Yap, Guam, and Kwaj, Avg Dry Season SPI vs ONI',\n",
    "               'Yap and Guam Avg Dry Season SPI vs ONI']\n",
    "ylab = ['SPI', 'SPI']\n",
    "xlab = ['ONI (C)', 'ONI (c)']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharex=True, \n",
    "                        tight_layout=True,  # trims margins\n",
    "                        figsize=(12, 8))\n",
    "\n",
    "fname = 'Time'\n",
    "#axs[0].set_title(fname)\n",
    "#lines_list = [] we dont really use this\n",
    "for yvar, xvar, tit, ax, y, x in zip(varlist,varlist_2, plot_titles, axs, ylab, xlab):\n",
    "    #cor = ' Corr=' + str('%.4f' % round(np.corrcoef(var,var2)[0][1],4))\n",
    "    ax.set_title(tit, fontsize = 12)\n",
    "    scatter = ax.scatter(xvar, yvar, c='k', label = '1966-2016')\n",
    "    ax.set_ylabel(y, color='k')\n",
    "    ax.set_ylim(-3,3)\n",
    "    ax.set_xlim(-2.5,2.5)\n",
    "    ax.set_xlabel(x, color='k')\n",
    "    ax.grid(True)\n",
    "    \n",
    "    year_list = [ 1984, 2001, 2006, 2009, 2013]\n",
    "    dry_y = np.empty(len(year_list))\n",
    "    dry_x = np.empty(len(year_list))\n",
    "    non_dry_year_list = [1985, 1986, 1996, 1997, 2014]\n",
    "    non_dry_y = np.empty(len(non_dry_year_list))\n",
    "    non_dry_x = np.empty(len(non_dry_year_list))\n",
    "    \n",
    "    la_nina_list =  [1989, 1999, 2000, 2008, 2011]\n",
    "    lanina_y = np.empty(len(la_nina_list))\n",
    "    lanina_x = np.empty(len(la_nina_list))\n",
    "    \n",
    "    for year in range(1966,2017):\n",
    "        \n",
    "        if year in year_list:\n",
    "            i = year_list.index(year)\n",
    "            dry_y[i] = yvar[year]\n",
    "            dry_x[i] = xvar[year]\n",
    "            #scatter = ax.scatter(xvar[year], yvar[year], c='r', label = 'Members of Dry Composite')\n",
    "         \n",
    "        elif year in la_nina_list:\n",
    "            i = la_nina_list.index(year)\n",
    "            lanina_y[i] = yvar[year]\n",
    "            lanina_x[i] = xvar[year]\n",
    "            \n",
    "        elif year in non_dry_year_list:\n",
    "            i = non_dry_year_list.index(year)\n",
    "            non_dry_y[i] = yvar[year]\n",
    "            non_dry_x[i] = xvar[year]\n",
    "            \n",
    "    scatter = ax.scatter(dry_x, dry_y, c='r', label = 'Members of Dry Composite')\n",
    "    scatter = ax.scatter(non_dry_x, non_dry_y, c='deepskyblue', label = 'Members of Non Dry Composite')\n",
    "    scatter = ax.scatter(lanina_x, lanina_y, c='b', label = 'Members of La Nina Composite')\n",
    "    \n",
    "#     year_labs = [str(x) for x in list(np.arange(1979,2017))]\n",
    "    \n",
    "#     for year, x, y in zip(year_labs, xvar, yvar):\n",
    "#         ax.annotate(year,xy=(x,y), xytext = (-20,0),\n",
    "#                    textcoords = 'offset points',\n",
    "#                    #textcoords = 'figure fraction', \n",
    "#                    ha = 'right', va='bottom', fontsize = 10,\n",
    "#                    arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    ax.set_ylim([-3,3])\n",
    "    \n",
    "    # Reduce the number of y-axis ticks:\n",
    "    ax.locator_params(axis='y', nbins=4)\n",
    "fig.savefig('scatterplots_3_station_SPI_v_3_saip_station_SPI.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stdev of the kwajalein rainfall\n",
    "Now we must calculate the stdev of the seasonal anomaly. The most straight forward way to calculate this may be unraveling the monthly anomaly into a series, using the seasonal_anomaly function and reshaping the series back into a matrix, then calculate the stdev of the columns of that matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here we restructure the seaqsonal anomaly time series into matices for easier logical selection\n",
    "kwajalein_seasonal_anom_matrix = kwajalein_seasonal_anom.reshape(51, 12)\n",
    "kwajalein_seasonal_total_matrix = kwajalein_seasonal_total.reshape(51, 12)\n",
    "oni_period_matrix = oni_period.reshape(51,12)\n",
    "\n",
    "#Here we calculate the stdev of eac column of the matrix this is the stdev of seasonal rainfall anomaly for each season\n",
    "kwajalein_season_std = kwajalein_seasonal_anom_matrix.std(axis=0)\n",
    "#we repeat the row 51 times to have a matrix the same size as the data matrix and the oni matrix\n",
    "kwajalein_season_std_matrix = np.tile(kwajalein_season_std,(51,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplication of conditions for composite membership\n",
    "\n",
    "## first for the rainfall and ONI conditions only\n",
    "\n",
    "Here we apply the condition for dry and very dry seasons\n",
    "\n",
    "Very dry is considered less than 4 inches a month, 12 inches a season or 305mm\n",
    "\n",
    "Dry is considered less than 8 inches a month, 24 inches a season or 610mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond_1stdev = kwajalein_seasonal_total_matrix <= 305\n",
    "cond_oni = oni_period_matrix <= -0.1\n",
    "cond_verydry_cool = np.logical_and(cond_1stdev, cond_oni)\n",
    "\n",
    "cond_05stdev = kwajalein_seasonal_total_matrix <= 610\n",
    "cond_oni = oni_period_matrix <= -0.1\n",
    "cond_dry_cool = np.logical_and(cond_05stdev, cond_oni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nos for the pattern correlation conditions too\n",
    "\n",
    "### we use only the 90% test level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cond_verydry_cool_90patcor = np.logical_and.reduce((cond_1stdev[:-1,:], cond_oni[:-1,:], pat_cor_90_test_lev))\n",
    "#cond_dry_cool_90patcor = np.logical_and.reduce((cond_05stdev[:-1,:], cond_oni[:-1,:], pat_cor_90_test_lev))\n",
    "\n",
    "cond_verydry_cool_90patcor = np.logical_and(cond_verydry_cool[:-1,:], pat_cor_90_test_lev)\n",
    "cond_dry_cool_90patcor = np.logical_and(cond_dry_cool[:-1,:], pat_cor_90_test_lev)\n",
    "\n",
    "#cond_verydry_cool_90patcor = np.logical_and(cond_1stdev[:-1,:], cond_oni[:-1,:], pat_cor_90_test_lev)\n",
    "#cond_dry_cool_90patcor = np.logical_and(cond_05stdev[:-1,:], cond_oni[:-1,:], pat_cor_90_test_lev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create the years selected tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Put ONI data into a pandas table\n",
    "season_list = ['DJF' , 'JFM' , 'FMA',\n",
    "               'MAM' , 'AMJ' , 'MJJ',\n",
    "               'JJA' , 'JAS' , 'ASO',\n",
    "               'SON' , 'OND' , 'NDJ']\n",
    "\n",
    "def oni_color(val):\n",
    "    \n",
    "    if val >= 0.5:\n",
    "        color = 'red'\n",
    "    elif val <= -0.5 :\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "\n",
    "\n",
    "ONI_df_color = ONI_df.style.applymap(oni_color)\n",
    "\n",
    "ONI_df_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def color_cells_dry(data, color = 'yellow', axis = None):\n",
    "    \n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    \n",
    "    return pd.DataFrame(np.where(cond_dry_cool[:-1,:], attr, ''),\n",
    "                       index = data.index,\n",
    "                       columns = data.columns)\n",
    "\n",
    "def color_cells_verydry(data, color = 'darkorange', axis = None):\n",
    "    \n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    \n",
    "    return pd.DataFrame(np.where(cond_verydry_cool[:-1,:], attr, ''),\n",
    "                       index = data.index,\n",
    "                       columns = data.columns)\n",
    "\n",
    "\n",
    "ONI_df_color_back = ONI_df.style.\\\n",
    "                                apply(color_cells_dry, axis = None).\\\n",
    "                                apply(color_cells_verydry, axis = None)\n",
    "        \n",
    "ONI_df_color_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def color_cells_dry(data, color = 'yellow', axis = None):\n",
    "    \n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    \n",
    "    return pd.DataFrame(np.where(cond_dry_cool[:-1,:], attr, ''),\n",
    "                       index = data.index,\n",
    "                       columns = data.columns)\n",
    "\n",
    "def color_cells_verydry(data, color = 'darkorange', axis = None):\n",
    "    \n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    \n",
    "    return pd.DataFrame(np.where(cond_verydry_cool[:-1,:], attr, ''),\n",
    "                       index = data.index,\n",
    "                       columns = data.columns)\n",
    "\n",
    "\n",
    "Kwaj_seasonal_total_rain_df = pd.DataFrame(kwajalein_seasonal_total_matrix[:-1,:], columns = season_list, index = range(1966,2016))\n",
    "\n",
    "Kwaj_color_back = Kwaj_seasonal_total_rain_df.style.\\\n",
    "                                apply(color_cells_dry, axis = None).\\\n",
    "                                apply(color_cells_verydry, axis = None)\n",
    "        \n",
    "Kwaj_color_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Kwaj_mon_rain_df = pd.DataFrame(stations.Kwajalein.rainfall[:-1,:], columns = season_list, index = range(1966,2016))\n",
    "\n",
    "Kwaj_color_back = Kwaj_mon_rain_df.style.\\\n",
    "                                apply(color_cells_dry, axis = None).\\\n",
    "                                apply(color_cells_verydry, axis = None)\n",
    "        \n",
    "Kwaj_color_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pp = PdfPages('Total_rainfall_Dry_and_VeryDry_seasons.pdf')\n",
    "\n",
    "# Calculate some sizes for formatting - constants are arbitrary - play around\n",
    "nrows, ncols = len(ONI_df)+1, len(ONI_df.columns) + 10\n",
    "hcell, wcell = 0.2, 0.4\n",
    "hpad, wpad = 0.05, 0   \n",
    "\n",
    "#put the table on a correctly sized figure    \n",
    "fig=plt.figure(figsize=(ncols*wcell+wpad, nrows*hcell+hpad))\n",
    "plt.gca().axis('off')\n",
    "\n",
    "#print_out_cell_colours = np.where(cond_dry_cool[:-1,:], 'yellow', 'white')\n",
    "print_out_cell_colours = np.where(cond_dry_cool[:-1,:], 'yellow', 'white')\n",
    "print_out_cell_colours = np.where(cond_verydry_cool[:-1,:], 'darkorange', print_out_cell_colours )\n",
    "\n",
    "matplotlib_tab = pd.tools.plotting.table(plt.gca(),ONI_df, \n",
    "                                         cellColours = print_out_cell_colours,\n",
    "                                         loc='center')\n",
    "\n",
    "plt.suptitle(\"Total Seasonal Rainfall\")\n",
    "\n",
    "pp.savefig()\n",
    "plt.close()\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = PdfPages('Total_rainfall_Dry_and_VeryDry_90patcor_seasons.pdf')\n",
    "\n",
    "# Calculate some sizes for formatting - constants are arbitrary - play around\n",
    "nrows, ncols = len(ONI_df)+1, len(ONI_df.columns) + 10\n",
    "hcell, wcell = 0.2, 0.4\n",
    "hpad, wpad = 0.05, 0   \n",
    "\n",
    "#put the table on a correctly sized figure    \n",
    "fig=plt.figure(figsize=(ncols*wcell+wpad, nrows*hcell+hpad))\n",
    "plt.gca().axis('off')\n",
    "\n",
    "#print_out_cell_colours = np.where(cond_dry_cool[:-1,:], 'yellow', 'white')\n",
    "print_out_cell_colours = np.where(cond_dry_cool_90patcor, 'yellow', 'white')\n",
    "print_out_cell_colours = np.where(cond_verydry_cool_90patcor, 'darkorange', print_out_cell_colours )\n",
    "\n",
    "matplotlib_tab = pd.tools.plotting.table(plt.gca(),ONI_df, \n",
    "                                         cellColours = print_out_cell_colours,\n",
    "                                         loc='center')    \n",
    "\n",
    "plt.suptitle(\"Total Seasonal Rainfall and 90 patcor\")\n",
    "\n",
    "pp.savefig()\n",
    "plt.close()\n",
    "\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now for the maps of individual years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotting_function(color_field, contour_field, u_wnd, v_wnd, \n",
    "                          color_field_name, case_name, target_dir, *argv, save = 'yes'):    \n",
    "    \n",
    "    #here basemap is producing a strange behaviour\n",
    "    m = Basemap(projection='merc', llcrnrlat=-50.1, urcrnrlat=50.01,\n",
    "                        llcrnrlon=80, urcrnrlon=300, lat_ts=0, resolution='c')\n",
    "\n",
    "    with open('mapcache.pk', mode='wb') as f:\n",
    "        pickle.dump(m, f)\n",
    "\n",
    "    ## Tweak the subplot specifications.  \n",
    "\n",
    "    subplotparams = dict(left=0.03, right=0.88,\n",
    "                         bottom=0.015, top=0.94,\n",
    "                         wspace=0.05, hspace=0.001)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(3,3, #sharex=True,\n",
    "                        figsize=(13, 7.8),\n",
    "                        gridspec_kw=subplotparams,\n",
    "                       )\n",
    "\n",
    "    mm = range(9)\n",
    "\n",
    "    for mon, pax in zip(mm, axs.flat):\n",
    "\n",
    "        with open('mapcache.pk', 'rb') as f:\n",
    "            m = pickle.load(f)\n",
    "        m.ax = pax\n",
    "\n",
    "        #reverse the coolwarm palatte to make blue rainy and red dry\n",
    "        cmap = plt.get_cmap('BrBG')\n",
    "        bounds = [-2.5,-2, -1.5,-1.25, -1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 2, 2.5]\n",
    "\n",
    "\n",
    "        x, y = m(*np.meshgrid(PREC_precip_longitudes, PREC_precip_latitudes))\n",
    "        im = m.contourf(x, y, color_field[mon,:,:], levels=bounds, cmap=cmap,\n",
    "                        extend='both')\n",
    "\n",
    "        x_hgt, y_hgt = m(*np.meshgrid(ncep_longitudes, ncep_latitudes))\n",
    "        #hgt_bounds = np.arange(-40,40,1)\n",
    "        hgt_bounds = [-80, -70,-60, -50, -40, \n",
    "                      -30, -20, -10,-8, -6, \n",
    "                      -4, -2, -1,0, 1, 2, 4, \n",
    "                      6, 8, 10, 20, 30,\n",
    "                      40, 50, 60, 70, 80]\n",
    "        hgt_bound_0 = [0]\n",
    "        im_hgt = m.contour(x_hgt, y_hgt, contour_field[mon,:,:], levels=hgt_bounds,\n",
    "                           linewidths=0.5, colors='k')\n",
    "        im_hgt = m.contour(x_hgt, y_hgt, contour_field[mon,:,:], levels=hgt_bound_0,\n",
    "                       linewidths=0.9, colors='k')\n",
    "\n",
    "\n",
    "        # transform vectors to projection grid.\n",
    "        uproj, vproj, xx, yy = m.rotate_vector(u_wnd[mon,:,:], \n",
    "                                               v_wnd[mon,:,:], \n",
    "                                               ncep_longitudes, \n",
    "                                               ncep_latitudes,\n",
    "                                               returnxy=True)\n",
    "        # now plot every other vector\n",
    "        Q = m.quiver(xx[::2,::2], yy[::2,::2], \n",
    "                     uproj[::2,::2], vproj[::2,::2],\n",
    "                     scale=20, scale_units='inches')\n",
    "\n",
    "        m.drawcoastlines()\n",
    "        \n",
    "        if box_coords in argv:\n",
    "            x1,y1 = m(box_coords[2], box_coords[1])\n",
    "            x2,y2 = m(box_coords[2], box_coords[0])\n",
    "            x3,y3 = m(box_coords[3], box_coords[0])\n",
    "            x4,y4 = m(box_coords[3], box_coords[1])\n",
    "            \n",
    "            p = Polygon([(x1,y1), (x2,y2), (x3,y3), (x4,y4)], \n",
    "                        edgecolor='b', facecolor = 'none', linewidth = 2)\n",
    "            m.ax.add_patch(p)\n",
    "\n",
    "        \n",
    "        parallels = np.arange(-90, 90, 30)\n",
    "        meridians = np.arange(-180, 180, 60)\n",
    "        if pax in axs.flat[::3]:\n",
    "            m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "        else:\n",
    "            m.drawparallels(parallels, labels = [0, 0, 0, 0], fontsize=8)\n",
    "\n",
    "        if pax in axs.flat[:6]:\n",
    "            m.drawmeridians(meridians, labels = [0, 0, 0, 0], fontsize=8)\n",
    "        if pax in axs.flat[6:]:\n",
    "            m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "        #m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "        #m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "        pax.set_title(color_field_name+\" Seasonal Anom \" +season_list[mon])\n",
    "\n",
    "    #cax, kw = mpl.colorbar.make_axes([ax for ax in axs.flat])\n",
    "    ##  This method of making an Axes for the cbar interacts very badly with\n",
    "    ##  basemap, so just make one manually.  This also gives more control, so\n",
    "    ##  it looks nicer.\n",
    "    left = subplotparams['right'] + 0.02\n",
    "    bottom = subplotparams['bottom'] + 0.05\n",
    "    width = 0.015\n",
    "    height = subplotparams['top'] - subplotparams['bottom'] - 0.1\n",
    "\n",
    "    cax = fig.add_axes([left, bottom, width, height])\n",
    "    cb = plt.colorbar(im, cax=cax)\n",
    "    cb.set_label('Precip Anomaly mm/day')\n",
    "\n",
    "    ## EF: The quiverkey needs to be made using an axes in which a quiver is\n",
    "    ##     drawn so that it has the right transform information.  Otherwise\n",
    "    ##     it won't get the length right.\n",
    "    qkx = left + (1 - left) / 4\n",
    "    qky = bottom + height + 0.025\n",
    "    qk = pax.quiverkey(Q, qkx, qky, 10, '10 m/s', \n",
    "                       coordinates='figure',\n",
    "                       labelpos='N',\n",
    "                       labelsep=0.07, \n",
    "                       fontproperties=dict(size='small'),\n",
    "                      )\n",
    "    \n",
    "    plt.suptitle(str(case_name)+\" \"+color_field_name+\" SST 850HGT WND seasonal anomaly\")\n",
    "    \n",
    "    if save == 'yes':\n",
    "\n",
    "        fig.savefig(target_dir+str(case_name)+\"_\"+color_field_name+\"_PRECIP_850HGT_WND_seasonal_anomaly.pdf\")\n",
    "        fig.savefig(target_dir+str(case_name)+\"_\"+color_field_name+\"_PRECIP_850HGT_WND_seasonal_anomaly.png\")\n",
    "        #fig.savefig(\"VERY_DRY_COMPOSITE_SST_850HGT_WND_seasonal_anomaly_%04d-%02d.pdf\" % (year, mon))\n",
    "        plt.close()# no need for dpi\n",
    "    \n",
    "\n",
    "    \n",
    "def sst_plotting_function(color_field, contour_field, u_wnd, v_wnd, \n",
    "                          color_field_name, case_name, target_dir, *argv, save = 'yes'):    \n",
    "    \n",
    "    #here basemap is producing a strange behaviour\n",
    "    m = Basemap(projection='merc', llcrnrlat=-50.1, urcrnrlat=50.01,\n",
    "                        llcrnrlon=80, urcrnrlon=300, lat_ts=0, resolution='c')\n",
    "\n",
    "    with open('mapcache.pk', mode='wb') as f:\n",
    "        pickle.dump(m, f)\n",
    "\n",
    "    ## Tweak the subplot specifications.  \n",
    "\n",
    "    subplotparams = dict(left=0.03, right=0.88,\n",
    "                         bottom=0.015, top=0.94,\n",
    "                         wspace=0.05, hspace=0.001)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(3,3, #sharex=True,\n",
    "                        figsize=(13, 7.8),\n",
    "                        gridspec_kw=subplotparams,\n",
    "                       )\n",
    "\n",
    "    mm = range(9)\n",
    "\n",
    "    for mon, pax in zip(mm, axs.flat):\n",
    "\n",
    "        with open('mapcache.pk', 'rb') as f:\n",
    "            m = pickle.load(f)\n",
    "        m.ax = pax\n",
    "\n",
    "        #reverse the coolwarm palatte to make blue rainy and red dry\n",
    "        cmap = cm.coolwarm\n",
    "        bounds = [-2, -1.5,-1.25, -1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 2]\n",
    "\n",
    "\n",
    "        x, y = m(*np.meshgrid(ersst_longitudes, ersst_latitudes))\n",
    "        im = m.contourf(x, y, color_field[mon,:,:], levels=bounds, cmap=cmap,\n",
    "                        extend='both')\n",
    "\n",
    "        x_hgt, y_hgt = m(*np.meshgrid(ncep_longitudes, ncep_latitudes))\n",
    "        #hgt_bounds = np.arange(-40,40,1)\n",
    "        hgt_bounds = [-80, -70,-60, -50, -40, \n",
    "                      -30, -20, -10,-8, -6, \n",
    "                      -4, -2, -1,0, 1, 2, 4, \n",
    "                      6, 8, 10, 20, 30,\n",
    "                      40, 50, 60, 70, 80]\n",
    "        hgt_bound_0 = [0]\n",
    "        im_hgt = m.contour(x_hgt, y_hgt, contour_field[mon,:,:], levels=hgt_bounds,\n",
    "                           linewidths=0.5, colors='k')\n",
    "        im_hgt = m.contour(x_hgt, y_hgt, contour_field[mon,:,:], levels=hgt_bound_0,\n",
    "                       linewidths=0.9, colors='k')\n",
    "\n",
    "\n",
    "        # transform vectors to projection grid.\n",
    "        uproj, vproj, xx, yy = m.rotate_vector(u_wnd[mon,:,:], \n",
    "                                               v_wnd[mon,:,:], \n",
    "                                               ncep_longitudes, \n",
    "                                               ncep_latitudes,\n",
    "                                               returnxy=True)\n",
    "        # now plot every other vector\n",
    "        Q = m.quiver(xx[::2,::2], yy[::2,::2], \n",
    "                     uproj[::2,::2], vproj[::2,::2],\n",
    "                     scale=20, scale_units='inches')\n",
    "\n",
    "        m.drawcoastlines()\n",
    "        \n",
    "        #draw the box\n",
    "        #lons = range(180,200,2.5)\n",
    "        #lats = \n",
    "        #m.drawgreatcircle(180,20,180,0,linewidth = 2, color = 'b')\n",
    "        \n",
    "        if box_coords in argv:\n",
    "            x1,y1 = m(box_coords[2], box_coords[1])\n",
    "            x2,y2 = m(box_coords[2], box_coords[0])\n",
    "            x3,y3 = m(box_coords[3], box_coords[0])\n",
    "            x4,y4 = m(box_coords[3], box_coords[1])\n",
    "            \n",
    "            p = Polygon([(x1,y1), (x2,y2), (x3,y3), (x4,y4)], \n",
    "                        edgecolor='b', facecolor = 'none', linewidth = 2)\n",
    "            m.ax.add_patch(p)\n",
    "            #plt.gca().add_patch(p)\n",
    "\n",
    "        \n",
    "        parallels = np.arange(-90, 90, 30)\n",
    "        meridians = np.arange(-180, 180, 60)\n",
    "        if pax in axs.flat[::3]:\n",
    "            m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "        else:\n",
    "            m.drawparallels(parallels, labels = [0, 0, 0, 0], fontsize=8)\n",
    "\n",
    "        if pax in axs.flat[:6]:\n",
    "            m.drawmeridians(meridians, labels = [0, 0, 0, 0], fontsize=8)\n",
    "        if pax in axs.flat[6:]:\n",
    "            m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "        #m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "        #m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "        pax.set_title(color_field_name+\" Seasonal Anom \" +season_list[mon])\n",
    "\n",
    "    #cax, kw = mpl.colorbar.make_axes([ax for ax in axs.flat])\n",
    "    ##  This method of making an Axes for the cbar interacts very badly with\n",
    "    ##  basemap, so just make one manually.  This also gives more control, so\n",
    "    ##  it looks nicer.\n",
    "    left = subplotparams['right'] + 0.02\n",
    "    bottom = subplotparams['bottom'] + 0.05\n",
    "    width = 0.015\n",
    "    height = subplotparams['top'] - subplotparams['bottom'] - 0.1\n",
    "\n",
    "    cax = fig.add_axes([left, bottom, width, height])\n",
    "    cb = plt.colorbar(im, cax=cax)\n",
    "    cb.set_label('SST Anomaly Deg C')\n",
    "\n",
    "    ## EF: The quiverkey needs to be made using an axes in which a quiver is\n",
    "    ##     drawn so that it has the right transform information.  Otherwise\n",
    "    ##     it won't get the length right.\n",
    "    qkx = left + (1 - left) / 4\n",
    "    qky = bottom + height + 0.025\n",
    "    qk = pax.quiverkey(Q, qkx, qky, 10, '10 m/s', \n",
    "                       coordinates='figure',\n",
    "                       labelpos='N',\n",
    "                       labelsep=0.07, \n",
    "                       fontproperties=dict(size='small'),\n",
    "                      )\n",
    "    \n",
    "    plt.suptitle(str(case_name)+\" \"+color_field_name+\" SST 850HGT WND seasonal anomaly\")\n",
    "    \n",
    "    if save == 'yes':\n",
    "        fig.savefig(target_dir+str(case_name)+\"_\"+color_field_name+\"_SST_850HGT_WND_seasonal_anomaly.pdf\")\n",
    "        fig.savefig(target_dir+str(case_name)+\"_\"+color_field_name+\"_SST_850HGT_WND_seasonal_anomaly.png\")\n",
    "        #fig.savefig(\"VERY_DRY_COMPOSITE_SST_850HGT_WND_seasonal_anomaly_%04d-%02d.pdf\" % (year, mon))\n",
    "        plt.close()# no need for dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "box_coords =[]\n",
    "\n",
    "year_list = [1975, 1981, 1984, 1986, 1989, 1996, 1997, 1999, 2000, 2001, 2002, 2006, 2008, 2009, 2012, 2013]\n",
    "\n",
    "season_list = ['DJF' , 'JFM' , 'FMA',\n",
    "               'MAM' , 'AMJ' , 'MJJ',\n",
    "               'JJA' , 'JAS' , 'ASO',\n",
    "               'SON' , 'OND' , 'NDJ']\n",
    "\n",
    "target_dir = \"./total_rainfall_composite_member_maps/\"\n",
    "\n",
    "for year in year_list:\n",
    "\n",
    "        sst_selection = ((sst_ca.ymdhms[:, 0] == year))\n",
    "        sst_selection = np.nonzero(sst_selection)[0]\n",
    "        sst_colorfield= sst_seasonal_anom.s_anom[sst_selection]\n",
    "\n",
    "        PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == year))\n",
    "        PREC_precip_selection = np.nonzero(PREC_precip_selection)[0]\n",
    "        PREC_precip_color_field = PREC_precip_seasonal_anom.s_anom[PREC_precip_selection]\n",
    "\n",
    "        selection = ((uwnd_ca.ymdhms[:, 0] == year))\n",
    "        selection = np.nonzero(selection)[0]\n",
    "        uwnd= uwnd_seasonal_anom.s_anom[selection]\n",
    "        vwnd = vwnd_seasonal_anom.s_anom[selection]\n",
    "        hgt_field = hgt_seasonal_anom.s_anom[selection]\n",
    "\n",
    "        plotting_function(PREC_precip_color_field, hgt_field, uwnd, vwnd, \n",
    "                          'PREC', year, target_dir, save = 'yes')\n",
    "        \n",
    "        sst_plotting_function(sst_colorfield, hgt_field, uwnd, vwnd, \n",
    "                             'ERSST', year, target_dir, save = 'yes')\n",
    "\n",
    "\n",
    "        if year >=1979:\n",
    "            precip_selection = ((precip_ca.ymdhms[:, 0] == year))\n",
    "            precip_selection = np.nonzero(precip_selection)[0]\n",
    "            precip_color_field= precip_seasonal_anom.s_anom[precip_selection]\n",
    "            \n",
    "            plotting_function(precip_color_field, hgt_field, uwnd, vwnd, \n",
    "                             'GPCP', year, target_dir, save = 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Here ^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year = 1984\n",
    "\n",
    "target_dir = \"./composite_member_maps/\"\n",
    "\n",
    "sst_selection = ((sst_ca.ymdhms[:, 0] == year))\n",
    "sst_selection = np.nonzero(sst_selection)[0]\n",
    "sst_colorfield= sst_seasonal_anom.s_anom[sst_selection]\n",
    "\n",
    "PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == year))\n",
    "PREC_precip_selection = np.nonzero(PREC_precip_selection)[0]\n",
    "PREC_precip_color_field = PREC_precip_seasonal_anom.s_anom[PREC_precip_selection]\n",
    "\n",
    "selection = ((uwnd_ca.ymdhms[:, 0] == year))\n",
    "selection = np.nonzero(selection)[0]\n",
    "uwnd= uwnd_seasonal_anom.s_anom[selection]\n",
    "vwnd = vwnd_seasonal_anom.s_anom[selection]\n",
    "hgt_field = hgt_seasonal_anom.s_anom[selection]\n",
    "\n",
    "plotting_function(PREC_precip_color_field, hgt_field, \n",
    "                 uwnd, vwnd, \n",
    "                 'PREC', year,\n",
    "                 target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "template = env.get_template(\"table_template.html\")\n",
    "\n",
    "#template_vars = {\"title\" : \"Sales Funnel Report - National\",\n",
    "#                 \"national_pivot_table\": ONI_df_color_back.to_html()}\n",
    "\n",
    "#html_out = template.render(template_vars)\n",
    "\n",
    "from weasyprint import HTML\n",
    "#HTML(string=html_out).write_pdf(\"report.pdf\")\n",
    "\n",
    "#HTML(string=ONI_df_color_back.render()).write_pdf(\"test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xhtml2pdf import pisa             # this is the module that will do the work\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Utility function\n",
    "def convertHtmlToPdf(sourceHtml, outputFilename):\n",
    "    # open output file for writing (truncated binary)\n",
    "    resultFile = open(outputFilename, \"w+b\")\n",
    "\n",
    "    # convert HTML to PDF\n",
    "    pisaStatus = pisa.CreatePDF(\n",
    "            sourceHtml,                # the HTML to convert\n",
    "            dest=resultFile,           # file handle to recieve result\n",
    "            path='.')                  # this path is needed so relative paths for \n",
    "                                       # temporary image sources work\n",
    "\n",
    "    # close output file\n",
    "    resultFile.close()                 # close output file\n",
    "\n",
    "    # return True on success and False on errors\n",
    "    return pisaStatus.err\n",
    "\n",
    "# Define your data\n",
    "    sourceHtml = '<html><head>'         \n",
    "    # add some table CSS in head\n",
    "    sourceHtml += '''<style>\n",
    "                     table, td, th {\n",
    "                           border-style: double;\n",
    "                           border-width: 3px;\n",
    "                     }\n",
    "\n",
    "                     td,th {\n",
    "                           padding: 5px;\n",
    "                     }\n",
    "                     </style>'''\n",
    "    sourceHtml += '</head><body>'\n",
    "\n",
    "    # Add the dataframe\n",
    "    sourceHtml += '\\n<p>' + ONI_df_color_back.to_html() + '</p>'\n",
    "\n",
    "\n",
    "    sourceHtml += '</body></html>'\n",
    "    outputFilename = 'test.pdf'\n",
    "\n",
    "    convertHtmlToPdf(sourceHtml, outputFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = plt.cm.BuPu(np.linspace(0, 0.5, 5))\n",
    "colors\n",
    "#ONI_df_color_back.to_excel('test.xlsx')\n",
    "\n",
    "test = np.where(cond_verydry_cool[:-1,:], 'yellow', '')\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(ONI_df_color_back))\n",
    "\n",
    "f = open('test.html', 'w')\n",
    "\n",
    "f.write(ONI_df_color_back.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from weasyprint import HTML\n",
    "HTML(string=ONI_df_color_back.render()).write_pdf(\"test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import table\n",
    "\n",
    "ax = plt.subplot(111, frame_on = False)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "table(ax, ONI_df)\n",
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_color_cells_dry(data,cond_matrix = cond_dry_cool[:-1,:] ,color = 'yellow'):\n",
    "    \n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    \n",
    "    return pd.DataFrame(np.where(cond_matrix, attr, ''),\n",
    "                       index = data.index,\n",
    "                       columns = data.columns)\n",
    "\n",
    "test = test_color_cells_dry(ONI_df_color)\n",
    "#ONI_df_color_back = ONI_df_color.style.apply(test_color_cells_dry, axis = None)\n",
    "#print(type(test))\n",
    "#print(test)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Put ONI data into a pandas table\n",
    "season_list = ['DJF' , 'JFM' , 'FMA',\n",
    "               'MAM' , 'AMJ' , 'MJJ',\n",
    "               'JJA' , 'JAS' , 'ASO',\n",
    "               'SON' , 'OND' , 'NDJ']\n",
    "\n",
    "\n",
    "\n",
    "def color_cells(val):\n",
    "    \n",
    "    background_color = 'yellow' if cond_dry_cool else ''\n",
    "    background_color = 'red' if cond_verydry_cool else ''\n",
    "    \n",
    "    return 'background-color: %s' % background_color \n",
    "\n",
    "\n",
    "ONI_df = pd.DataFrame(oni_period_matrix[:-1,], columns = season_list, index = range(1966,2016))\n",
    "ONI_df_color = ONI_df.style.applymap(color_cells)\n",
    "#ONI_df\n",
    "\n",
    "#heat_map = np.empty(np.shape(oni_period_matrix[:-1,]), dtype = 'object')\n",
    "#heat_map = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "#heat_map[:] = np.NAN\n",
    "\n",
    "#if cond_dry_cool[:-1,:]:\n",
    "heat_map_d = cond_dry_cool[:-1,:].astype(int)\n",
    "heat_map_vd = cond_verydry_cool[:-1,:].astype(int)\n",
    "\n",
    "heat_map_all = heat_map_d + heat_map_vd\n",
    "\n",
    "#for dry, very_dry, value in np.nditer([cond_dry_cool[:-1,:],cond_verydry_cool[:-1,:],heat_map], flags=['refs_ok']):\n",
    "    #print(dry, very_dry, value)\n",
    "    \n",
    "#    if dry:\n",
    "#        heat_map(value) = 'yellow' \n",
    "        #print(dry, value)\n",
    "#    if very_dry:\n",
    "#        vheat_map(value) = 'red'\n",
    "        #print(very_dry, value)\n",
    "    \n",
    "fig,axs = plt.subplots(2,1)\n",
    "#ax = fig.add_subplot(111,frameon =True, xticks=[], yticks=[])\n",
    "\n",
    "the_table = axs[0].table(cellText = ONI_df.values, \n",
    "                      rowLabels=ONI_df.index, colLabels = ONI_df.columns,\n",
    "                      cellColours = plt.cm.hot(heat_map_all) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(heat_map_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection_matrix = cond_verydry_cool\n",
    "\n",
    "for i in range(len(selection_matrix.ravel())):\n",
    "    if selection_matrix.ravel()[i]:\n",
    "        print(stations.Kwajalein.ymdhms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection_matrix = cond_verydry_cool_90patcor\n",
    "\n",
    "for i in range(len(selection_matrix.ravel())):\n",
    "    if selection_matrix.ravel()[i]:\n",
    "        print(stations.Kwajalein.ymdhms[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below we set up the matrices that will contain the composite members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "season_members_verydry = np.zeros(12)\n",
    "gpcp_season_members_verydry = np.zeros(12)\n",
    "\n",
    "sst_composite_members_verydry = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "sst_composite_members_verydry[:] = np.NAN\n",
    "\n",
    "precip_composite_members_verydry = np.empty([50,12, len(precip_latitudes), len(precip_longitudes)])\n",
    "precip_composite_members_verydry[:] = np.NAN\n",
    "\n",
    "PREC_precip_composite_members_verydry = np.empty([50,12, len(PREC_precip_latitudes), len(PREC_precip_longitudes)])\n",
    "PREC_precip_composite_members_verydry[:] = np.NAN\n",
    "\n",
    "uwnd_composite_members_verydry = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "uwnd_composite_members_verydry[:] = np.NAN\n",
    "vwnd_composite_members_verydry = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "vwnd_composite_members_verydry[:] = np.NAN\n",
    "hgt_composite_members_verydry = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "hgt_composite_members_verydry[:] = np.NAN\n",
    "\n",
    "season_members_dry = np.zeros(12)\n",
    "gpcp_season_members_dry = np.zeros(12)\n",
    "\n",
    "precip_composite_members_dry = np.empty([50,12, len(precip_latitudes), len(precip_longitudes)])\n",
    "precip_composite_members_dry[:] = np.NAN\n",
    "\n",
    "sst_composite_members_dry = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "sst_composite_members_dry[:] = np.NAN\n",
    "\n",
    "PREC_precip_composite_members_dry = np.empty([51,12, len(PREC_precip_latitudes), len(PREC_precip_longitudes)])\n",
    "PREC_precip_composite_members_dry[:] = np.NAN\n",
    "\n",
    "uwnd_composite_members_dry = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "uwnd_composite_members_dry[:] = np.NAN\n",
    "vwnd_composite_members_dry = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "vwnd_composite_members_dry[:] = np.NAN\n",
    "hgt_composite_members_dry = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "hgt_composite_members_dry[:] = np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "season_members_verydry_90patcor = np.zeros(12)\n",
    "gpcp_season_members_verydry_90patcor = np.zeros(12)\n",
    "\n",
    "precip_composite_members_verydry_90patcor = np.empty([50,12, len(precip_latitudes), len(precip_longitudes)])\n",
    "precip_composite_members_verydry_90patcor[:] = np.NAN\n",
    "\n",
    "sst_composite_members_verydry_90patcor = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "sst_composite_members_verydry_90patcor[:] = np.NAN\n",
    "\n",
    "PREC_precip_composite_members_verydry_90patcor = np.empty([50,12, len(PREC_precip_latitudes), len(PREC_precip_longitudes)])\n",
    "PREC_precip_composite_members_verydry_90patcor[:] = np.NAN\n",
    "\n",
    "uwnd_composite_members_verydry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "uwnd_composite_members_verydry_90patcor[:] = np.NAN\n",
    "vwnd_composite_members_verydry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "vwnd_composite_members_verydry_90patcor[:] = np.NAN\n",
    "hgt_composite_members_verydry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "hgt_composite_members_verydry_90patcor[:] = np.NAN\n",
    "\n",
    "season_members_dry_90patcor = np.zeros(12)\n",
    "gpcp_season_members_dry_90patcor = np.zeros(12)\n",
    "\n",
    "precip_composite_members_dry_90patcor = np.empty([50,12, len(precip_latitudes), len(precip_longitudes)])\n",
    "precip_composite_members_dry_90patcor[:] = np.NAN\n",
    "\n",
    "sst_composite_members_dry_90patcor = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "sst_composite_members_dry_90patcor[:] = np.NAN\n",
    "\n",
    "PREC_precip_composite_members_dry_90patcor = np.empty([50,12, len(PREC_precip_latitudes), len(PREC_precip_longitudes)])\n",
    "PREC_precip_composite_members_dry_90patcor[:] = np.NAN\n",
    "\n",
    "uwnd_composite_members_dry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "uwnd_composite_members_dry_90patcor[:] = np.NAN\n",
    "vwnd_composite_members_dry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "vwnd_composite_members_dry_90patcor[:] = np.NAN\n",
    "hgt_composite_members_dry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "hgt_composite_members_dry_90patcor[:] = np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#season_members_verydry_90patcor = np.zeros(12)\n",
    "\n",
    "#sst_composite_members_verydry_90patcor = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "#sst_composite_members_verydry_90patcor[:] = np.NAN\n",
    "#uwnd_composite_members_verydry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "#uwnd_composite_members_verydry_90patcor[:] = np.NAN\n",
    "#vwnd_composite_members_verydry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "#vwnd_composite_members_verydry_90patcor[:] = np.NAN\n",
    "#hgt_composite_members_verydry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "#hgt_composite_members_verydry_90patcor[:] = np.NAN\n",
    "\n",
    "#season_members_dry_90patcor = np.zeros(12)\n",
    "\n",
    "#sst_composite_members_dry_90patcor = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "#sst_composite_members_dry_90patcor[:] = np.NAN\n",
    "#uwnd_composite_members_dry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "#uwnd_composite_members_dry_90patcor[:] = np.NAN\n",
    "#vwnd_composite_members_dry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "#vwnd_composite_members_dry_90patcor[:] = np.NAN\n",
    "#hgt_composite_members_dry_90patcor = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "#hgt_composite_members_dry_90patcor[:] = np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_range = range(1966,2016)\n",
    "for year in year_range:\n",
    "    for m in range(1,13):\n",
    "        \n",
    "        if cond_verydry_cool[year_range.index(year),m-1]:   \n",
    "            \n",
    "            \n",
    "            #print(year,year_range.index(year),m,cond_verydry_cool[year_range.index(year),m-1])\n",
    "\n",
    "            sst_selection = ((sst_ca.ymdhms[:, 0] == year) & (sst_ca.ymdhms[:, 1] == m))\n",
    "            sst_selection = np.nonzero(sst_selection)[0][0]\n",
    "            sst_composite_members_verydry[year_range.index(year),m-1,:,:] = sst_seasonal_anom.s_anom[sst_selection]\n",
    "            \n",
    "            PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == year) & (PREC_precip_ca.ymdhms[:, 1] == m))\n",
    "            PREC_precip_selection = np.nonzero(PREC_precip_selection)[0][0]\n",
    "            PREC_precip_composite_members_verydry[year_range.index(year),m-1,:,:] = PREC_precip_seasonal_anom.s_anom[PREC_precip_selection]\n",
    "            \n",
    "            selection = ((uwnd_ca.ymdhms[:, 0] == year) & (uwnd_ca.ymdhms[:, 1] == m))\n",
    "            selection = np.nonzero(selection)[0][0]\n",
    "            uwnd_composite_members_verydry[year_range.index(year),m-1,:,:] = uwnd_seasonal_anom.s_anom[selection]\n",
    "            vwnd_composite_members_verydry[year_range.index(year),m-1,:,:] = vwnd_seasonal_anom.s_anom[selection]\n",
    "            hgt_composite_members_verydry[year_range.index(year),m-1,:,:] = hgt_seasonal_anom.s_anom[selection]\n",
    "            \n",
    "            season_members_verydry[m-1] = season_members_verydry[m-1] +1\n",
    "            \n",
    "            if year >=1979:\n",
    "                precip_selection = ((precip_ca.ymdhms[:, 0] == year) & (precip_ca.ymdhms[:, 1] == m))\n",
    "                precip_selection = np.nonzero(precip_selection)[0][0]\n",
    "                precip_composite_members_verydry[year_range.index(year),m-1,:,:] = precip_seasonal_anom.s_anom[precip_selection]\n",
    "                       \n",
    "                gpcp_season_members_verydry[m-1] = gpcp_season_members_verydry[m-1] +1\n",
    "                \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "for year in year_range:\n",
    "\n",
    "    for m in range(1,13):\n",
    "        \n",
    "        if cond_verydry_cool_90patcor[year_range.index(year),m-1]:   \n",
    "            \n",
    "            #print(year,year_range.index(year),m,cond_verydry_cool[year_range.index(year),m-1])\n",
    "\n",
    "            sst_selection = ((sst_ca.ymdhms[:, 0] == year) & (sst_ca.ymdhms[:, 1] == m))\n",
    "            sst_selection = np.nonzero(sst_selection)[0][0]\n",
    "            sst_composite_members_verydry_90patcor[year_range.index(year),m-1,:,:] = sst_seasonal_anom.s_anom[sst_selection]\n",
    "            \n",
    "            PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == year) & (PREC_precip_ca.ymdhms[:, 1] == m))\n",
    "            PREC_precip_selection = np.nonzero(PREC_precip_selection)[0][0]\n",
    "            PREC_precip_composite_members_verydry_90patcor[year_range.index(year),m-1,:,:] = PREC_precip_seasonal_anom.s_anom[PREC_precip_selection]\n",
    "            \n",
    "            selection = ((uwnd_ca.ymdhms[:, 0] == year) & (uwnd_ca.ymdhms[:, 1] == m))\n",
    "            selection = np.nonzero(selection)[0][0]\n",
    "            uwnd_composite_members_verydry_90patcor[year_range.index(year),m-1,:,:] = uwnd_seasonal_anom.s_anom[selection]\n",
    "            vwnd_composite_members_verydry_90patcor[year_range.index(year),m-1,:,:] = vwnd_seasonal_anom.s_anom[selection]\n",
    "            hgt_composite_members_verydry_90patcor[year_range.index(year),m-1,:,:] = hgt_seasonal_anom.s_anom[selection]\n",
    "            \n",
    "            season_members_verydry_90patcor[m-1] = season_members_verydry_90patcor[m-1] +1\n",
    "            \n",
    "            if year >=1979:\n",
    "                precip_selection = ((precip_ca.ymdhms[:, 0] == year) & (precip_ca.ymdhms[:, 1] == m))\n",
    "                precip_selection = np.nonzero(precip_selection)[0][0]\n",
    "                precip_composite_members_verydry_90patcor[year_range.index(year),m-1,:,:] = precip_seasonal_anom.s_anom[precip_selection]\n",
    "                       \n",
    "                gpcp_season_members_verydry_90patcor[m-1] = gpcp_season_members_verydry_90patcor[m-1] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(np.shape(PREC_precip_seasonal_anom.s_anom))\n",
    "#PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == 1999) & (PREC_precip_ca.ymdhms[:, 1] == m))\n",
    "#PREC_precip_selection = np.nonzero(PREC_precip_selection)[0][0]\n",
    "#print(PREC_precip_seasonal_anom.s_anom[PREC_precip_selection])\n",
    "\n",
    "#year_range = range(1966,2016)\n",
    "#for year in year_range:\n",
    "#    print(year_range.index(year), year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_range = range(1966,2016)\n",
    "for year in year_range:\n",
    "    for m in range(1,13):\n",
    "        \n",
    "        if cond_dry_cool[year_range.index(year),m-1]:   \n",
    "            \n",
    "            \n",
    "            #print(year,year_range.index(year),m,cond_verydry_cool[year_range.index(year),m-1])\n",
    "\n",
    "            sst_selection = ((sst_ca.ymdhms[:, 0] == year) & (sst_ca.ymdhms[:, 1] == m))\n",
    "            sst_selection = np.nonzero(sst_selection)[0][0]\n",
    "            sst_composite_members_dry[year_range.index(year),m-1,:,:] = sst_seasonal_anom.s_anom[sst_selection]\n",
    "            \n",
    "            PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == year) & (PREC_precip_ca.ymdhms[:, 1] == m))\n",
    "            PREC_precip_selection = np.nonzero(PREC_precip_selection)[0][0]\n",
    "            PREC_precip_composite_members_dry[year_range.index(year),m-1,:,:] = PREC_precip_seasonal_anom.s_anom[PREC_precip_selection]\n",
    "            \n",
    "            selection = ((uwnd_ca.ymdhms[:, 0] == year) & (uwnd_ca.ymdhms[:, 1] == m))\n",
    "            selection = np.nonzero(selection)[0][0]\n",
    "            uwnd_composite_members_dry[year_range.index(year),m-1,:,:] = uwnd_seasonal_anom.s_anom[selection]\n",
    "            vwnd_composite_members_dry[year_range.index(year),m-1,:,:] = vwnd_seasonal_anom.s_anom[selection]\n",
    "            hgt_composite_members_dry[year_range.index(year),m-1,:,:] = hgt_seasonal_anom.s_anom[selection]\n",
    "            \n",
    "            season_members_dry[m-1] = season_members_dry[m-1] +1\n",
    "            \n",
    "            if year >=1979:\n",
    "                precip_selection = ((precip_ca.ymdhms[:, 0] == year) & (precip_ca.ymdhms[:, 1] == m))\n",
    "                precip_selection = np.nonzero(precip_selection)[0][0]\n",
    "                precip_composite_members_dry[year_range.index(year),m-1,:,:] = precip_seasonal_anom.s_anom[precip_selection]\n",
    "                       \n",
    "                gpcp_season_members_dry[m-1] = gpcp_season_members_dry[m-1] +1\n",
    "                \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "for year in year_range:\n",
    "\n",
    "    for m in range(1,13):\n",
    "        \n",
    "        if cond_dry_cool_90patcor[year_range.index(year),m-1]:   \n",
    "            \n",
    "            #print(year,year_range.index(year),m,cond_verydry_cool[year_range.index(year),m-1])\n",
    "\n",
    "            sst_selection = ((sst_ca.ymdhms[:, 0] == year) & (sst_ca.ymdhms[:, 1] == m))\n",
    "            sst_selection = np.nonzero(sst_selection)[0][0]\n",
    "            sst_composite_members_dry_90patcor[year_range.index(year),m-1,:,:] = sst_seasonal_anom.s_anom[sst_selection]\n",
    "            \n",
    "            PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == year) & (PREC_precip_ca.ymdhms[:, 1] == m))\n",
    "            PREC_precip_selection = np.nonzero(PREC_precip_selection)[0][0]\n",
    "            PREC_precip_composite_members_dry_90patcor[year_range.index(year),m-1,:,:] = PREC_precip_seasonal_anom.s_anom[PREC_precip_selection]\n",
    "            \n",
    "            selection = ((uwnd_ca.ymdhms[:, 0] == year) & (uwnd_ca.ymdhms[:, 1] == m))\n",
    "            selection = np.nonzero(selection)[0][0]\n",
    "            uwnd_composite_members_dry_90patcor[year_range.index(year),m-1,:,:] = uwnd_seasonal_anom.s_anom[selection]\n",
    "            vwnd_composite_members_dry_90patcor[year_range.index(year),m-1,:,:] = vwnd_seasonal_anom.s_anom[selection]\n",
    "            hgt_composite_members_dry_90patcor[year_range.index(year),m-1,:,:] = hgt_seasonal_anom.s_anom[selection]\n",
    "            \n",
    "            season_members_dry_90patcor[m-1] = season_members_dry_90patcor[m-1] +1\n",
    "            \n",
    "            if year >=1979:\n",
    "                precip_selection = ((precip_ca.ymdhms[:, 0] == year) & (precip_ca.ymdhms[:, 1] == m))\n",
    "                precip_selection = np.nonzero(precip_selection)[0][0]\n",
    "                precip_composite_members_dry_90patcor[year_range.index(year),m-1,:,:] = precip_seasonal_anom.s_anom[precip_selection]\n",
    "                       \n",
    "                gpcp_season_members_dry_90patcor[m-1] = gpcp_season_members_dry_90patcor[m-1] +1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precip_composite_verydry = np.nanmean(precip_composite_members_verydry, axis=0)\n",
    "sst_composite_verydry = np.nanmean(sst_composite_members_verydry, axis=0)\n",
    "PREC_precip_composite_verydry = np.nanmean(PREC_precip_composite_members_verydry, axis=0)\n",
    "uwnd_composite_verydry = np.nanmean(uwnd_composite_members_verydry, axis=0)\n",
    "vwnd_composite_verydry = np.nanmean(vwnd_composite_members_verydry, axis=0)\n",
    "hgt_composite_verydry = np.nanmean(hgt_composite_members_verydry, axis=0)\n",
    "\n",
    "precip_composite_dry = np.nanmean(precip_composite_members_dry, axis=0)\n",
    "sst_composite_dry = np.nanmean(sst_composite_members_dry, axis=0)\n",
    "PREC_precip_composite_dry  = np.nanmean(PREC_precip_composite_members_dry, axis=0)\n",
    "uwnd_composite_dry = np.nanmean(uwnd_composite_members_dry, axis=0)\n",
    "vwnd_composite_dry = np.nanmean(vwnd_composite_members_dry, axis=0)\n",
    "hgt_composite_dry = np.nanmean(hgt_composite_members_dry, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precip_composite_verydry_90patcor = np.nanmean(precip_composite_members_verydry_90patcor, axis=0)\n",
    "sst_composite_verydry_90patcor = np.nanmean(sst_composite_members_verydry_90patcor, axis=0)\n",
    "PREC_precip_composite_verydry_90patcor = np.nanmean(PREC_precip_composite_members_verydry_90patcor, axis=0)\n",
    "uwnd_composite_verydry_90patcor = np.nanmean(uwnd_composite_members_verydry_90patcor, axis=0)\n",
    "vwnd_composite_verydry_90patcor = np.nanmean(vwnd_composite_members_verydry_90patcor, axis=0)\n",
    "hgt_composite_verydry_90patcor = np.nanmean(hgt_composite_members_verydry_90patcor, axis=0)\n",
    "\n",
    "precip_composite_dry_90patcor = np.nanmean(precip_composite_members_dry_90patcor, axis=0)\n",
    "sst_composite_dry_90patcor = np.nanmean(sst_composite_members_dry_90patcor, axis=0)\n",
    "PREC_precip_composite_dry_90patcor = np.nanmean(PREC_precip_composite_members_dry_90patcor, axis=0)\n",
    "uwnd_composite_dry_90patcor = np.nanmean(uwnd_composite_members_dry_90patcor, axis=0)\n",
    "vwnd_composite_dry_90patcor = np.nanmean(vwnd_composite_members_dry_90patcor, axis=0)\n",
    "hgt_composite_dry_90patcor = np.nanmean(hgt_composite_members_dry_90patcor, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "season_list = ['DJF' , 'JFM' , 'FMA',\n",
    "               'MAM' , 'AMJ' , 'MJJ',\n",
    "               'JJA' , 'JAS' , 'ASO',\n",
    "               'SON' , 'OND' , 'NDJ']\n",
    "\n",
    "month_list = ['Jan' , 'Feb' , 'Mar',\n",
    "              'Apr' , 'May' , 'Jun',\n",
    "              'Jul' , 'Aug' , 'Sep',\n",
    "              'Oct' , 'Nov' , 'Dec']\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 113\n",
    "plt.rcParams['axes.titlesize'] = 'small'\n",
    "plt.rcParams['ytick.labelsize'] = 'small'  # for colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here I define the plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotting_function(color_field, contour_field, u_wnd, v_wnd, member_counter, color_field_name, case_name):    \n",
    "    \n",
    "    #here basemap is producing a strange behaviour\n",
    "    m = Basemap(projection='merc', llcrnrlat=-50.1, urcrnrlat=50.01,\n",
    "                        llcrnrlon=80, urcrnrlon=300, lat_ts=0, resolution='c')\n",
    "\n",
    "    with open('mapcache.pk', mode='wb') as f:\n",
    "        pickle.dump(m, f)\n",
    "\n",
    "    ## Tweak the subplot specifications.  \n",
    "\n",
    "    subplotparams = dict(left=0.03, right=0.88,\n",
    "                         bottom=0.03, top=0.96,\n",
    "                         wspace=0.05, hspace=0.1)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(3,3, #sharex=True,\n",
    "                        figsize=(13, 7.8),\n",
    "                        gridspec_kw=subplotparams,\n",
    "                       )\n",
    "\n",
    "    mm = range(2,11)\n",
    "\n",
    "    for mon, pax in zip(mm, axs.flat):\n",
    "\n",
    "        with open('mapcache.pk', 'rb') as f:\n",
    "            m = pickle.load(f)\n",
    "        m.ax = pax\n",
    "\n",
    "        #reverse the coolwarm palatte to make blue rainy and red dry\n",
    "        cmap = plt.get_cmap('BrBG')\n",
    "        bounds = [-2.5,-2, -1.5,-1.25, -1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 2, 2.5]\n",
    "\n",
    "\n",
    "        x, y = m(*np.meshgrid(PREC_precip_longitudes, PREC_precip_latitudes))\n",
    "        im = m.contourf(x, y, color_field[mon,:,:], levels=bounds, cmap=cmap,\n",
    "                        extend='both')\n",
    "\n",
    "        x_hgt, y_hgt = m(*np.meshgrid(ncep_longitudes, ncep_latitudes))\n",
    "        #hgt_bounds = np.arange(-40,40,1)\n",
    "        hgt_bounds = [-80, -70,-60, -50, -40, \n",
    "                      -30, -20, -10,-8, -6, \n",
    "                      -4, -2, -1,0, 1, 2, 4, \n",
    "                      6, 8, 10, 20, 30,\n",
    "                      40, 50, 60, 70, 80]\n",
    "        hgt_bound_0 = [0]\n",
    "        im_hgt = m.contour(x_hgt, y_hgt, contour_field[mon,:,:], levels=hgt_bounds,\n",
    "                           linewidths=0.5, colors='k')\n",
    "        im_hgt = m.contour(x_hgt, y_hgt, contour_field[mon,:,:], levels=hgt_bound_0,\n",
    "                       linewidths=0.9, colors='k')\n",
    "\n",
    "\n",
    "        # transform vectors to projection grid.\n",
    "        uproj, vproj, xx, yy = m.rotate_vector(u_wnd[mon,:,:], \n",
    "                                               v_wnd[mon,:,:], \n",
    "                                               ncep_longitudes, \n",
    "                                               ncep_latitudes,\n",
    "                                               returnxy=True)\n",
    "        # now plot every other vector\n",
    "        Q = m.quiver(xx[::2,::2], yy[::2,::2], \n",
    "                     uproj[::2,::2], vproj[::2,::2],\n",
    "                     scale=20, scale_units='inches')\n",
    "\n",
    "        m.drawcoastlines()\n",
    "        parallels = np.arange(-90, 90, 30)\n",
    "        meridians = np.arange(-180, 180, 60)\n",
    "        if pax in axs.flat[::3]:\n",
    "            m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "        else:\n",
    "            m.drawparallels(parallels, labels = [0, 0, 0, 0], fontsize=8)\n",
    "\n",
    "        if pax in axs.flat[:6]:\n",
    "            m.drawmeridians(meridians, labels = [0, 0, 0, 0], fontsize=8)\n",
    "        if pax in axs.flat[6:]:\n",
    "            m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "        #m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "        #m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "        pax.set_title(color_field_name+\" Seasonal Anom Comp \" +season_list[mon] + \" members \" + str(member_counter[mon]))\n",
    "\n",
    "    #cax, kw = mpl.colorbar.make_axes([ax for ax in axs.flat])\n",
    "    ##  This method of making an Axes for the cbar interacts very badly with\n",
    "    ##  basemap, so just make one manually.  This also gives more control, so\n",
    "    ##  it looks nicer.\n",
    "    left = subplotparams['right'] + 0.02\n",
    "    bottom = subplotparams['bottom'] + 0.05\n",
    "    width = 0.015\n",
    "    height = subplotparams['top'] - subplotparams['bottom'] - 0.1\n",
    "\n",
    "    cax = fig.add_axes([left, bottom, width, height])\n",
    "    cb = plt.colorbar(im, cax=cax)\n",
    "    cb.set_label('Precip Anomaly mm/day')\n",
    "\n",
    "    ## EF: The quiverkey needs to be made using an axes in which a quiver is\n",
    "    ##     drawn so that it has the right transform information.  Otherwise\n",
    "    ##     it won't get the length right.\n",
    "    qkx = left + (1 - left) / 4\n",
    "    qky = bottom + height + 0.025\n",
    "    qk = pax.quiverkey(Q, qkx, qky, 10, '10 m/s', \n",
    "                       coordinates='figure',\n",
    "                       labelpos='N',\n",
    "                       labelsep=0.07, \n",
    "                       fontproperties=dict(size='small'),\n",
    "                      )\n",
    "\n",
    "    fig.savefig(case_name+\"_\"+color_field_name+\"_PRECIP_850HGT_WND_seasonal_anomaly.pdf\")\n",
    "    fig.savefig(case_name+\"_\"+color_field_name+\"_PRECIP_850HGT_WND_seasonal_anomaly.png\")\n",
    "    #fig.savefig(\"VERY_DRY_COMPOSITE_SST_850HGT_WND_seasonal_anomaly_%04d-%02d.pdf\" % (year, mon))\n",
    "    plt.close()# no need for dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plotting_function(PREC_precip_composite_verydry, hgt_composite_verydry, \n",
    "#                  uwnd_composite_verydry, vwnd_composite_verydry, \n",
    "#                  season_members_verydry, 'PREC', \"Very_Dry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we plot the composites for the verydry cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verydry case composite with PREC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotting_function(PREC_precip_composite_verydry, hgt_composite_verydry, \n",
    "                  uwnd_composite_verydry, vwnd_composite_verydry, \n",
    "                  season_members_verydry, 'PREC', \"Very_Dry\")\n",
    "\n",
    "plotting_function(PREC_precip_composite_verydry_90patcor, hgt_composite_verydry_90patcor, \n",
    "                  uwnd_composite_verydry_90patcor, vwnd_composite_verydry_90patcor, \n",
    "                  season_members_verydry_90patcor, 'PREC', \"Very_Dry_90patcor\")\n",
    "\n",
    "plotting_function(PREC_precip_composite_dry, hgt_composite_dry, \n",
    "                  uwnd_composite_dry, vwnd_composite_dry, \n",
    "                  season_members_dry, 'PREC', \"Dry\")\n",
    "\n",
    "plotting_function(PREC_precip_composite_dry_90patcor, hgt_composite_dry_90patcor, \n",
    "                  uwnd_composite_dry_90patcor, vwnd_composite_dry_90patcor, \n",
    "                  season_members_dry_90patcor, 'PREC', \"Dry_90patcor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPCP verydry 90 patcor composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotting_function(precip_composite_verydry, hgt_composite_verydry, \n",
    "                  uwnd_composite_verydry, vwnd_composite_verydry, \n",
    "                  gpcp_season_members_verydry, 'GPCP', \"Very_Dry\")\n",
    "\n",
    "\n",
    "plotting_function(precip_composite_verydry_90patcor, hgt_composite_verydry_90patcor, \n",
    "                  uwnd_composite_verydry_90patcor, vwnd_composite_verydry_90patcor, \n",
    "                  gpcp_season_members_verydry_90patcor, 'GPCP', \"Very_Dry_90patcor\")\n",
    "\n",
    "plotting_function(precip_composite_dry, hgt_composite_dry, \n",
    "                  uwnd_composite_dry, vwnd_composite_dry, \n",
    "                  gpcp_season_members_dry, 'GPCP', \"Dry\")\n",
    "\n",
    "\n",
    "plotting_function(precip_composite_dry_90patcor, hgt_composite_dry_90patcor, \n",
    "                  uwnd_composite_dry_90patcor, vwnd_composite_dry_90patcor, \n",
    "                  gpcp_season_members_dry_90patcor, 'GPCP', \"Dry_90patcor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sst_plotting_function(sst_composite_verydry, hgt_composite_verydry, \n",
    "                      uwnd_composite_verydry, vwnd_composite_verydry, \n",
    "                      season_members_verydry, 'ERSST', \"Very_Dry\")\n",
    "\n",
    "\n",
    "sst_plotting_function(sst_composite_verydry_90patcor, hgt_composite_verydry_90patcor, \n",
    "                      uwnd_composite_verydry_90patcor, vwnd_composite_verydry_90patcor, \n",
    "                      season_members_verydry_90patcor, 'ERSST', \"Very_Dry_90patcor\")\n",
    "\n",
    "sst_plotting_function(sst_composite_dry, hgt_composite_dry, \n",
    "                      uwnd_composite_dry, vwnd_composite_dry, \n",
    "                      season_members_dry, 'ERSST', \"Dry\")\n",
    "\n",
    "\n",
    "sst_plotting_function(sst_composite_dry_90patcor, hgt_composite_dry_90patcor, \n",
    "                      uwnd_composite_dry_90patcor, vwnd_composite_dry_90patcor, \n",
    "                      season_members_dry_90patcor, 'ERSST', \"Dry_90patcor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the non dry composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond_non_dry = kwajalein_seasonal_anom_matrix >= 0* kwajalein_season_std_matrix\n",
    "cond_oni = oni_period_matrix <= -0.1\n",
    "cond_non_dry_cool = np.logical_and(cond_non_dry, cond_oni)\n",
    "\n",
    "precip_composite_members_non_dry = np.empty([50,12, len(precip_latitudes), len(precip_longitudes)])\n",
    "precip_composite_members_non_dry[:] = np.NAN\n",
    "\n",
    "sst_composite_members_non_dry = np.empty([50,12, len(ersst_latitudes), len(ersst_longitudes)])\n",
    "sst_composite_members_non_dry[:] = np.NAN\n",
    "\n",
    "PREC_precip_composite_members_non_dry = np.empty([50,12, len(PREC_precip_latitudes), len(PREC_precip_longitudes)])\n",
    "PREC_precip_composite_members_non_dry[:] = np.NAN\n",
    "\n",
    "uwnd_non_dry_composite_members = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "uwnd_non_dry_composite_members[:] = np.NAN\n",
    "vwnd_non_dry_composite_members = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "vwnd_non_dry_composite_members[:] = np.NAN\n",
    "hgt_non_dry_composite_members = np.empty([50,12,len(ncep_latitudes), len(ncep_longitudes)])\n",
    "hgt_non_dry_composite_members[:] = np.NAN\n",
    "\n",
    "gpcp_season_members_non_dry = np.zeros(12)\n",
    "season_members_non_dry = np.zeros(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_range = range(1966,2016)\n",
    "for year in year_range:\n",
    "    for m in range(1,13):\n",
    "        \n",
    "        if cond_non_dry_cool[year_range.index(year),m-1]:\n",
    "            \n",
    "            sst_selection = ((sst_ca.ymdhms[:, 0] == year) & (sst_ca.ymdhms[:, 1] == m))\n",
    "            sst_selection = np.nonzero(sst_selection)[0][0]\n",
    "            sst_composite_members_non_dry[year_range.index(year),m-1,:,:] = sst_seasonal_anom.s_anom[sst_selection]\n",
    "            \n",
    "            PREC_precip_selection = ((PREC_precip_ca.ymdhms[:, 0] == year) & (PREC_precip_ca.ymdhms[:, 1] == m))\n",
    "            PREC_precip_selection = np.nonzero(PREC_precip_selection)[0][0]\n",
    "            PREC_precip_composite_members_non_dry[year_range.index(year),m-1,:,:] = PREC_precip_seasonal_anom.s_anom[PREC_precip_selection]\n",
    "            \n",
    "            selection = ((uwnd_ca.ymdhms[:, 0] == year) & (uwnd_ca.ymdhms[:, 1] == m))\n",
    "            selection = np.nonzero(selection)[0][0]\n",
    "            uwnd_non_dry_composite_members[year_range.index(year),m-1,:,:] = uwnd_seasonal_anom.s_anom[selection]\n",
    "            vwnd_non_dry_composite_members[year_range.index(year),m-1,:,:] = vwnd_seasonal_anom.s_anom[selection]\n",
    "            hgt_non_dry_composite_members[year_range.index(year),m-1,:,:] = hgt_seasonal_anom.s_anom[selection]\n",
    "            \n",
    "            season_members_non_dry[m-1] = season_members_non_dry[m-1] +1\n",
    "            \n",
    "            if year >=1979:\n",
    "                precip_selection = ((precip_ca.ymdhms[:, 0] == year) & (precip_ca.ymdhms[:, 1] == m))\n",
    "                precip_selection = np.nonzero(precip_selection)[0][0]\n",
    "                precip_composite_members_non_dry[year_range.index(year),m-1,:,:] = precip_seasonal_anom.s_anom[precip_selection]\n",
    "                       \n",
    "                gpcp_season_members_non_dry[m-1] = gpcp_season_members_non_dry[m-1] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precip_non_dry_composite = np.nanmean(precip_composite_members_non_dry, axis=0)\n",
    "\n",
    "sst_non_dry_composite = np.nanmean(sst_composite_members_non_dry, axis=0)\n",
    "\n",
    "PREC_precip_non_dry_composite = np.nanmean(PREC_precip_composite_members_non_dry, axis=0)\n",
    "\n",
    "uwnd_non_dry_composite = np.nanmean(uwnd_non_dry_composite_members, axis=0)\n",
    "vwnd_non_dry_composite = np.nanmean(vwnd_non_dry_composite_members, axis=0)\n",
    "hgt_non_dry_composite = np.nanmean(hgt_non_dry_composite_members, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.shape(uwnd_non_dry_composite))\n",
    "print(np.shape(vwnd_non_dry_composite))\n",
    "print(np.shape(hgt_non_dry_composite))\n",
    "\n",
    "print(np.shape(precip_non_dry_composite))\n",
    "print(np.shape(PREC_precip_non_dry_composite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotting_function(PREC_precip_non_dry_composite, hgt_non_dry_composite, \n",
    "                  uwnd_non_dry_composite, vwnd_non_dry_composite, \n",
    "                  season_members_non_dry, 'PREC', \"Non_Dry\")\n",
    "\n",
    "plotting_function(precip_non_dry_composite, hgt_non_dry_composite, \n",
    "                  uwnd_non_dry_composite, vwnd_non_dry_composite, \n",
    "                  gpcp_season_members_non_dry, 'GPCP', \"Non_Dry\")\n",
    "\n",
    "sst_plotting_function(sst_non_dry_composite, hgt_non_dry_composite, \n",
    "                      uwnd_non_dry_composite, vwnd_non_dry_composite, \n",
    "                      season_members_non_dry, 'ERSST', \"Non_Dry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Here-------------------------^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here basemap is producing a strange behaviour\n",
    "m = Basemap(projection='merc', llcrnrlat=-50.1, urcrnrlat=50.01,\n",
    "                    llcrnrlon=80, urcrnrlon=300, lat_ts=0, resolution='c')\n",
    "\n",
    "with open('mapcache.pk', mode='wb') as f:\n",
    "    pickle.dump(m, f)\n",
    "\n",
    "## Tweak the subplot specifications.  \n",
    "\n",
    "subplotparams = dict(left=0.03, right=0.88,\n",
    "                     bottom=0.03, top=0.96,\n",
    "                     wspace=0.05, hspace=0.1)\n",
    "\n",
    "    \n",
    "fig, axs = plt.subplots(3,3, #sharex=True,\n",
    "                    figsize=(13, 7.8),\n",
    "                    gridspec_kw=subplotparams,\n",
    "                   )\n",
    "\n",
    "mm = range(2,11)\n",
    "\n",
    "for mon, pax in zip(mm, axs.flat):\n",
    "\n",
    "    with open('mapcache.pk', 'rb') as f:\n",
    "        m = pickle.load(f)\n",
    "    m.ax = pax\n",
    "\n",
    "    #reverse the coolwarm palatte to make blue rainy and red dry\n",
    "    cmap = cm.coolwarm\n",
    "    bounds = [-2, -1.5,-1.25, -1, -0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 2]\n",
    "    #norm = cols.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    #im = m.imshow(sst_transform,cmap=cm.coolwarm, interpolation = \"none\",norm=norm)\n",
    "\n",
    "    ##  EF: using an image gains nothing here, loses resolution, and adds complexity.\n",
    "    ##      Contouring is nicer.  If you wanted something image-like, it would\n",
    "    ##      be better to use pcolormesh--but there is no point when you are using\n",
    "    ##      discretized colors on a relatively fine lon/lat grid like this.\n",
    "\n",
    "    x, y = m(*np.meshgrid(ersst_longitudes, ersst_latitudes))\n",
    "    im = m.contourf(x, y, sst_non_dry_composite[mon,:,:], levels=bounds, cmap=cmap,\n",
    "                    extend='both')\n",
    "\n",
    "    x_hgt, y_hgt = m(*np.meshgrid(ncep_longitudes, ncep_latitudes))\n",
    "    #hgt_bounds = np.arange(-40,40,1)\n",
    "    hgt_bounds = [-80, -70,-60, -50, -40, \n",
    "                  -30, -20, -10,-8, -6, \n",
    "                  -4, -2, -1,0, 1, 2, 4, \n",
    "                  6, 8, 10, 20, 30,\n",
    "                  40, 50, 60, 70, 80]\n",
    "    im_hgt = m.contour(x_hgt, y_hgt, hgt_non_dry_composite[mon,:,:], levels=hgt_bounds,\n",
    "                       linewidths=0.5, colors='k')\n",
    "\n",
    "\n",
    "    # transform vectors to projection grid.\n",
    "    uproj, vproj, xx, yy = m.rotate_vector(uwnd_non_dry_composite[mon,:,:], \n",
    "                                           vwnd_non_dry_composite[mon,:,:], \n",
    "                                           ncep_longitudes, \n",
    "                                           ncep_latitudes,\n",
    "                                           returnxy=True)\n",
    "    # now plot every other vector\n",
    "    Q = m.quiver(xx[::2,::2], yy[::2,::2], \n",
    "                 uproj[::2,::2], vproj[::2,::2],\n",
    "                 scale=20, scale_units='inches')\n",
    "\n",
    "    m.drawcoastlines()\n",
    "    parallels = np.arange(-90, 90, 30)\n",
    "    meridians = np.arange(-180, 180, 60)\n",
    "    if pax in axs.flat[::3]:\n",
    "        m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "    else:\n",
    "        m.drawparallels(parallels, labels = [0, 0, 0, 0], fontsize=8)\n",
    "\n",
    "    if pax in axs.flat[:6]:\n",
    "        m.drawmeridians(meridians, labels = [0, 0, 0, 0], fontsize=8)\n",
    "    if pax in axs.flat[6:]:\n",
    "        m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "    #m.drawparallels(parallels, labels = [1, 0, 0, 1], fontsize=8)\n",
    "    #m.drawmeridians(meridians, labels = [1, 0, 0, 1], fontsize=8)\n",
    "\n",
    "    pax.set_title(\"Seasonal Anomaly Composite \" +season_list[mon] + \" members \" + str(season_members_non_dry[mon]))\n",
    "\n",
    "#cax, kw = mpl.colorbar.make_axes([ax for ax in axs.flat])\n",
    "##  This method of making an Axes for the cbar interacts very badly with\n",
    "##  basemap, so just make one manually.  This also gives more control, so\n",
    "##  it looks nicer.\n",
    "left = subplotparams['right'] + 0.02\n",
    "bottom = subplotparams['bottom'] + 0.05\n",
    "width = 0.015\n",
    "height = subplotparams['top'] - subplotparams['bottom'] - 0.1\n",
    "\n",
    "cax = fig.add_axes([left, bottom, width, height])\n",
    "cb = plt.colorbar(im, cax=cax)\n",
    "cb.set_label('SST C')\n",
    "\n",
    "## EF: The quiverkey needs to be made using an axes in which a quiver is\n",
    "##     drawn so that it has the right transform information.  Otherwise\n",
    "##     it won't get the length right.\n",
    "qkx = left + (1 - left) / 4\n",
    "qky = bottom + height + 0.025\n",
    "qk = pax.quiverkey(Q, qkx, qky, 10, '10 m/s', \n",
    "                   coordinates='figure',\n",
    "                   labelpos='N',\n",
    "                   labelsep=0.07, \n",
    "                   fontproperties=dict(size='small'),\n",
    "                  )\n",
    "\n",
    "fig.savefig(\"NON_DRY_COMPOSITE_SST_850HGT_WNDseasonal_anomaly.pdf\")\n",
    "#plt.close()# no need for dpi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
