{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import random as rm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copied from aludert's data faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_faker_2(N, m, b, c=1, gamma=0.0000001, rand_div = 'yes'):\n",
    "    \n",
    "    if rand_div == 'yes':\n",
    "        \n",
    "        cosine_sign_choice = rm.random()\n",
    "        \n",
    "        if cosine_sign_choice < 0.5:\n",
    "            cosine_sign = -1\n",
    "        else:\n",
    "            cosine_sign = 1\n",
    "            \n",
    "        cosine = cosine_sign * rm.random()\n",
    "        \n",
    "        angle = math.acos(cosine)\n",
    "        \n",
    "        m = math.sin(angle)/math.cos(angle)\n",
    "        \n",
    "        intercep_sign_choice = rm.random()\n",
    "        \n",
    "        if intercep_sign_choice < 0.5:\n",
    "            b_sign = -1\n",
    "        else:\n",
    "            b_sign = 1\n",
    "            \n",
    "        b = b_sign * rm.random()\n",
    "    \n",
    "    alpha = math.atan(m)\n",
    "    bd = gamma / math.cos(alpha)\n",
    "    \n",
    "    if 0<=abs(alpha)<45:\n",
    "        gamma_max = (1/math.cos(alpha))*c\n",
    "    elif 45<=abs(alpha)<90:\n",
    "        gamma_max = (1/math.sin(alpha))*c\n",
    "        \n",
    "    points = np.empty([N,3])\n",
    "        \n",
    "    if gamma > gamma_max:\n",
    "        print('gamma is greater than allowed gamma_max for this slope')\n",
    "        return points, m, b\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        good = 0\n",
    "        \n",
    "        while good == 0:\n",
    "        \n",
    "            x_sign_choice = rm.random()\n",
    "\n",
    "            if x_sign_choice < 0.5:\n",
    "                x_sign = -1\n",
    "            else:\n",
    "                x_sign = 1\n",
    "\n",
    "            x_i = x_sign * rm.random() *c\n",
    "            #---------------------------------------\n",
    "\n",
    "            y_sign_choice = rm.random()\n",
    "\n",
    "            if y_sign_choice < 0.5:\n",
    "                y_sign = -1\n",
    "            else:\n",
    "                y_sign = 1\n",
    "\n",
    "            y_i = y_sign * rm.random() *c\n",
    "            #----------------------------------------\n",
    "            \n",
    "            if y_i < m*x_i+b:\n",
    "                l_i = 1\n",
    "            elif y_i > m*x_i+b:\n",
    "                l_i = -1\n",
    "            \n",
    "            if l_i == 1 and y_i < m*x_i+(b-bd):\n",
    "                good = 1\n",
    "            elif l_i ==-1 and y_i > m*x_i+(b+bd):\n",
    "                good = 1\n",
    "                \n",
    "        points[i,0] = x_i\n",
    "        points[i,1] = y_i\n",
    "        points[i,2] = l_i\n",
    "         \n",
    "    return points, m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "step_function = lambda f: -1 if f <= 0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron(points, w=(0,0,0), eta=0.5, n_iter=10000, video='no', m=0, b=0, vid_dir = './vid'):\n",
    "    \n",
    "    test_training = np.ones([len(points),4])\n",
    "    test_training[:,1:] =  points\n",
    "    \n",
    "    misclassed = True\n",
    "    num_slope_adjusts = 0\n",
    "    n = 0\n",
    "    num_points_tested = 0\n",
    "    slope = 0\n",
    "    intercept = 0\n",
    "    \n",
    "    while (misclassed and n < n_iter):\n",
    "        n += 1\n",
    "        wrong_line = 0\n",
    "        \n",
    "        for test_val in test_training:\n",
    "            point = test_val[:3]\n",
    "            desired = test_val[3]\n",
    "            result = np.dot(w, point)\n",
    "            f = step_function(result)\n",
    "            num_points_tested += 1\n",
    "            \n",
    "            if f != desired:\n",
    "                wrong_line += 1\n",
    "                num_slope_adjusts += 1\n",
    "                w += eta * desired * point\n",
    "                \n",
    "                if w[2] != 0:\n",
    "                    slope = -(w[1] / w[2])\n",
    "                    intercept = -(w[0] / w[2])\n",
    "                else:\n",
    "                    slope = 0\n",
    "                    intercept = 0\n",
    "                \n",
    "                if video == 'yes':\n",
    "                        scatter_plot_vid(points, m, b, \n",
    "                                         slope, intercept, \n",
    "                                         num_points_tested, vid_dir = './vid')\n",
    "        \n",
    "        if wrong_line == 0: \n",
    "            misclassed = False\n",
    "\n",
    "        \n",
    "    return slope, intercept, n, num_slope_adjusts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 1: Number of weight vector adjustments vs Number of data points, N (eta=0.5, c=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 0\n",
    "N_list = []\n",
    "k_ave_list = []\n",
    "k_SDM_list = []\n",
    "i = 0\n",
    "num_trials = 1000\n",
    "for N in range(10, 10000, 1000):\n",
    "    k_list = []\n",
    "    N_list.append(N)\n",
    "    for i in range(num_trials):\n",
    "        points, m, b = data_faker_2(N, 1, 0, c=10, rand_div='no')\n",
    "        p_m, p_b, n, k = perceptron(points)\n",
    "        k_list.append(k)\n",
    "    k_ave = stat.mean(k_list)\n",
    "    k_SDM = stat.stdev(k_list) / math.sqrt(num_trials)\n",
    "    k_ave_list.append(k_ave)\n",
    "    k_SDM_list.append(k_SDM)\n",
    "    \n",
    "np.save('N_list.npy',N_list)\n",
    "np.save('k_ave_list.npy',k_ave_list)\n",
    "np.save('k_SDM_list.npy',k_SDM_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_plot_1 = plt.errorbar(N_list, k_ave_list, yerr=k_SDM_list, fmt='o', color='r')\n",
    "plt.title('')\n",
    "plt.xlabel('Number of data points')\n",
    "plt.ylabel('Number of weight vector adjustments')\n",
    "plt.savefig('Exp_1_large_N.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
